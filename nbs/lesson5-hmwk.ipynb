{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 20 newsgroups topic analysis\n",
    "\n",
    "Instead of repeating the IMDB sentiment analysis from the lesson (because frankly, I'm a little bored with sentiment analysis), I will attempt to apply a similar approach to deep-learning NLP classification to a dataset a coworker has recently been messing around with in `scikit-learn`: `sklearn.datasets.fetch_20newsgroups`.\n",
    "\n",
    "http://people.csail.mit.edu/jrennie/20Newsgroups/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "LESSON_HOME_DIR = current_dir + '/'\n",
    "DATA_HOME_DIR = LESSON_HOME_DIR + 'data/'\n",
    "\n",
    "DATASET_DIR = DATA_HOME_DIR + '20_newsgroup/'\n",
    "MODEL_DIR = DATASET_DIR + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(DATASET_DIR)\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "category_subset = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    'comp.os.ms-windows.misc',\n",
    "    'soc.religion.christian',\n",
    "]\n",
    "\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset = 'all',\n",
    "    categories = category_subset,\n",
    "    shuffle = True,\n",
    "    remove = ('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'soc.religion.christian']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target_names` are as requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3754,), (3754,), 3754)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.filenames.shape, newsgroups.target.shape, len(newsgroups.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras implements `get_word_index()` for the IMDB dataset, which returns an dictionary of word->index derived from a json file hosted on Amazon S3.\n",
    "\n",
    "It seems bizarre to me to host this when you can easily create it on-demand... anyway, sklearn doesn't provide this. So let's create our own index with `keras.preprocessing.text.Tokenizer` (https://keras.io/preprocessing/text/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.text\n",
    "import string\n",
    "\n",
    "# Workaround to add \"Unicode support for keras.preprocessing.text\"\n",
    "# (https://github.com/fchollet/keras/issues/1072#issuecomment-295470970)\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = string.maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "vocab_size = 20000\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=vocab_size)\n",
    "tokenizer.fit_on_texts(newsgroups.data) # builds the word index\n",
    "sequences = tokenizer.texts_to_sequences(newsgroups.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72905"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse the `word_index` with `idx2word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in word_index.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first review, both as a list of indices and as text reconstructed from the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24, 2, 60, 566, 52, 20, 4829, 3, 389, 2, 3000, 1339, 2, 155, 386, 84, 901, 76, 4, 115, 24, 2, 88, 566, 76, 92, 402, 3, 525, 12351, 101, 2, 155, 385, 6, 1685, 2454, 236, 93, 182, 118, 1350, 335, 7, 108, 5725, 2764, 6, 3000, 8981, 20, 396, 3, 118, 127, 2454, 6, 158, 182, 90, 4499, 14, 129, 11, 2274, 81, 4808, 234, 219, 92, 23, 10264, 5605, 6, 720, 10, 3000, 61, 783, 5464, 8, 5725, 7, 1736, 3, 239, 3, 1464, 55, 2, 579, 5464, 214, 701, 45, 91, 23, 2, 1802, 4, 11819, 5, 1464, 10, 2, 2694, 74, 318, 10232, 129, 386, 436, 5, 10837, 24, 11, 30, 3, 102, 1641, 11, 114, 332, 8, 2, 1598, 5, 858, 537, 9, 11, 1237, 96, 386, 95, 17, 23, 3, 952, 26, 8, 9, 15584, 121, 23, 219, 9951, 9845, 61, 2104, 95, 96, 5725, 11, 8, 5, 2828, 3, 2501, 197, 4, 127, 863, 720, 200, 102, 337, 127, 1576, 1021, 93, 15, 495, 2, 2157, 4, 94, 396, 3, 5777, 127, 9605, 720, 182, 118, 614, 2221, 60, 261, 3, 583, 8, 9, 135, 2, 154, 1464, 8, 210, 1464'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(map(str, sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'on'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"on the one hand there are advantages to having the liturgy stay the same john has described some of these on the other hand some people seem to start tuning out the same old and pay attention better when things get changed around i think innovative priests and liturgy committees are trying to get our attention and make things more meaningful for us it drives me crazy too different people have differing preferences and needs in liturgy my local parish is innovative i prefer to go to mass at the next parish over sometimes we don't have the option of attending a mass in the style which best suits us john put a smiley on it but to just offer it up probably is the solution a related issue that it sounds like john does not have to deal with is that spouses may have different liturgical tastes my husband does like innovative it is a challenge to meet both of our spiritual needs without just going our separate ways when you include the factor of also trying to satisfy our children's needs things get pretty complicated one thing to remember is that even the most mass is still mass\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2word[o] for o in sequences[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 'soc.religion.christian')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target[0], newsgroups.target_names[newsgroups.target[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the lengths of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158791, 0, 1493.157432072456)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lens = np.array(map(len, newsgroups.data))\n",
    "(lens.max(), lens.min(), lens.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird that there are sentences with 0 sequences (words) in them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices of arrays that do NOT satisfy np.nonzero\n",
    "nonzero_indices = np.unique(np.nonzero(sequences)[0])\n",
    "zero_indices = set(range(len(sequences))).difference(nonzero_indices)\n",
    "len(zero_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 101 sentences with no words. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], 'alt.atheism')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[64], newsgroups.target_names[newsgroups.target[64]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad (with zero) or truncate each sentence to make consistent length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "seq_len = 1000\n",
    "\n",
    "data = sequence.pad_sequences(sequences, maxlen=seq_len, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     8,   210,  1464],\n",
       "       [    0,     0,     0, ...,  3162,     8,    11],\n",
       "       [    0,     0,     0, ...,     2,   318,  1142],\n",
       "       ..., \n",
       "       [    0,     0,     0, ...,    47,     7,   740],\n",
       "       [ 1070,    11,     8, ...,  2565,   356,   129],\n",
       "       [    0,     0,     0, ..., 16529,   364,  8254]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's turn the labels into categorical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "newsgroups.target = to_categorical(np.asarray(newsgroups.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3754, 1000), (3754, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, newsgroups.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, newsgroups.target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2515, 1000), (1239, 1000), (2515, 4), (1239, 4))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single hidden layer NN\n",
    "\n",
    "The simplest model that tends to give reasonable results is a single hidden layer net. So let's try that. Note that we can't expect to get any useful results by feeding word ids directly into a neural net - so instead we use an embedding to replace them with a vector of 32 (initially random) floats for each word in the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# input_length => 1500-word reviews, 32 floats per word\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 32, input_length=seq_len),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(len(newsgroups.target_names), activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 1000, 32)      640000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 32000)         0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           3200100     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4)             404         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3840504\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.4164 - acc: 0.2958 - val_loss: 1.3311 - val_acc: 0.3858\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.2913 - acc: 0.3658 - val_loss: 1.2087 - val_acc: 0.4487\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.0958 - acc: 0.4680 - val_loss: 0.9064 - val_acc: 0.5908\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.7658 - acc: 0.6533 - val_loss: 0.7439 - val_acc: 0.6312\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.4885 - acc: 0.8278 - val_loss: 0.6599 - val_acc: 0.6941\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.2883 - acc: 0.9205 - val_loss: 0.5805 - val_acc: 0.7530\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.1777 - acc: 0.9610 - val_loss: 0.5618 - val_acc: 0.7554\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.1319 - acc: 0.9714 - val_loss: 0.5579 - val_acc: 0.7667\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.0974 - acc: 0.9734 - val_loss: 0.5636 - val_acc: 0.7554\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.0861 - acc: 0.9753 - val_loss: 0.5887 - val_acc: 0.7490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efbb37acb90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a mid-70s validation accuracy.. Good? Bad?\n",
    "\n",
    "Here are some accuracies [from an official `sklearn` example](http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html) that classifies documents by topics using a bag-of-words approach:\n",
    "\n",
    "```\n",
    "[('RidgeClassifier', 0.89726533628972649),\n",
    " ('Perceptron', 0.88543976348854403),\n",
    " ('PassiveAggressiveClassifier', 0.90613451589061345),\n",
    " ('KNeighborsClassifier', 0.85809312638580926),\n",
    " ('RandomForestClassifier', 0.83813747228381374),\n",
    " ('LinearSVC', 0.90022172949002222),\n",
    " ('SGDClassifier', 0.90096082779009612),\n",
    " ('LinearSVC', 0.87287509238728755),\n",
    " ('SGDClassifier', 0.88543976348854403),\n",
    " ('SGDClassifier', 0.89874353288987441),\n",
    " ('NearestCentroid', 0.85513673318551364),\n",
    " ('MultinomialNB', 0.90022172949002222),\n",
    " ('BernoulliNB', 0.88396156688839611),\n",
    " ('Pipeline', 0.8810051736881005)]\n",
    " \n",
    " mean: 0.88311688311688319\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, not a good result in comparison with much simpler approaches. Training accuracy is high, but testing accuracy is much poorer.\n",
    "\n",
    "As a sanity check, I also ran code from [`pretrained_word_embeddings.py`](https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py) (from Keras's examples repository) which also runs against `20_newsgroups` (not the `sklearn` version though), and it was able to achieve:\n",
    "\n",
    "    loss: 0.3784 - acc: 0.8734 - val_loss: 0.9177 - val_acc: 0.7257\n",
    "after 10 epochs - again, not as accurate as the 'shallow', bag-of-words models - but comparable to the results I'm receiving here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single conv layer with max pooling\n",
    "\n",
    "A CNN is likely to work better, since it's designed to take advantage of ordered data. We'll need to use a 1D CNN, since a sequence of words is 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "conv1 = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2),\n",
    "    Dropout(0.4),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    MaxPooling1D(5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(len(newsgroups.target_names), activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 1000, 100)     2000000     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1000, 100)     0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 996, 128)      64128       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 996, 128)      0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 199, 128)      0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25472)         0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           3260544     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 128)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4)             516         dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5325188\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "conv1.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "conv1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010000000474974513"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.optimizer.lr.get_value().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.4193 - acc: 0.3026 - val_loss: 1.3534 - val_acc: 0.3721\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.3302 - acc: 0.3475 - val_loss: 1.2985 - val_acc: 0.4116\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.1868 - acc: 0.4223 - val_loss: 1.0413 - val_acc: 0.5020\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.9257 - acc: 0.5169 - val_loss: 0.8350 - val_acc: 0.5650\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7874 - acc: 0.5773 - val_loss: 0.7488 - val_acc: 0.6481\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6623 - acc: 0.6835 - val_loss: 0.6472 - val_acc: 0.7490\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5284 - acc: 0.7809 - val_loss: 0.5500 - val_acc: 0.7756\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4189 - acc: 0.8338 - val_loss: 0.5270 - val_acc: 0.7748\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3315 - acc: 0.8791 - val_loss: 0.5171 - val_acc: 0.7667\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2724 - acc: 0.9026 - val_loss: 0.5359 - val_acc: 0.7837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efbae22f190>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/4\n",
      "2515/2515 [==============================] - 4s - loss: 0.2564 - acc: 0.9054 - val_loss: 0.5452 - val_acc: 0.7837\n",
      "Epoch 2/4\n",
      "2515/2515 [==============================] - 4s - loss: 0.2232 - acc: 0.9137 - val_loss: 0.5260 - val_acc: 0.8015\n",
      "Epoch 3/4\n",
      "2515/2515 [==============================] - 4s - loss: 0.2021 - acc: 0.9193 - val_loss: 0.5464 - val_acc: 0.7910\n",
      "Epoch 4/4\n",
      "2515/2515 [==============================] - 4s - loss: 0.1948 - acc: 0.9221 - val_loss: 0.6848 - val_acc: 0.7724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efbae22fb90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 4s - loss: 0.1794 - acc: 0.9344 - val_loss: 0.5481 - val_acc: 0.7990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efbae22f710>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good improvement over the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pre-trained vectors\n",
    "\n",
    "You may want to look at wordvectors.ipynb before moving on.\n",
    "\n",
    "In this section, we replicate the previous CNN, but using pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "def get_glove_dataset(dataset):\n",
    "    \"\"\"Download the requested glove dataset from files.fast.ai\n",
    "    and return a location that can be passed to load_vectors.\n",
    "    \"\"\"\n",
    "    # see wordvectors.ipynb for info on how these files were\n",
    "    # generated from the original glove data.\n",
    "    md5sums = {'6B.50d': '8e1557d1228decbda7db6dfd81cd9909',\n",
    "               '6B.100d': 'c92dbbeacde2b0384a43014885a60b2c',\n",
    "               '6B.200d': 'af271b46c04b0b2e41a84d8cd806178d',\n",
    "               '6B.300d': '30290210376887dcc6d0a5a6374d8255'}\n",
    "    glove_path = os.path.abspath('data/glove/results')\n",
    "    %mkdir -p $glove_path\n",
    "    return get_file(dataset,\n",
    "                    'http://files.fast.ai/models/glove/' + dataset + '.tgz',\n",
    "                    cache_subdir=glove_path,\n",
    "                    md5_hash=md5sums.get(dataset, None),\n",
    "                    untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import load_array\n",
    "import pickle\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untaring file...\n"
     ]
    }
   ],
   "source": [
    "vecs, words, wordidx = load_vectors(get_glove_dataset('6B.100d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glove word ids and imdb word ids use different indexes. So we create a simple function that creates an embedding matrix using the indexes from imdb, and the embeddings from glove (where they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from numpy.random import normal\n",
    "\n",
    "def create_emb():\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "\n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word and word in wordidx:\n",
    "            src_idx = wordidx[word]\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb_model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2, \n",
    "              weights=[emb], trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(128, 5, border_mode='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(4, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: I started seeing lines like `4s - loss: nan - acc: 0.6783 - val_loss: nan - val_acc: 0.2131` where in the previous epoch, `val_acc` was twice that amount. A [quick search on the forums](http://forums.fast.ai/t/why-are-my-losses-nan/2931/2) surfaced this explanation:\n",
    "\n",
    "    \"There is one thing that doesn't look quite right: the final activation is not compatible with that loss function. Categorical cross-entropy expects a 'softmax' activation in the final layer, not 'sigmoid'. Consider changing that to see what happens.\"\n",
    "    \n",
    "**Categorical cross-entropy expects a `softmax` activation in the final layer, not `sigmoid`.** So I switched to `softmax`... I don't recall ever learning this information, however. Should ponder why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 1000, 100)     0           embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1000, 100)     0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 1000, 128)     64128       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 1000, 128)     0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 500, 128)      0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 64000)         0           maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 100)           6400100     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 100)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 4)             404         dropout_7[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 6464632\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.4046 - acc: 0.3324 - val_loss: 1.2151 - val_acc: 0.4746\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.1134 - acc: 0.4608 - val_loss: 0.9404 - val_acc: 0.5174\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.9463 - acc: 0.5082 - val_loss: 0.8698 - val_acc: 0.5456\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.8846 - acc: 0.5348 - val_loss: 0.8030 - val_acc: 0.5811\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.8320 - acc: 0.5750 - val_loss: 0.7712 - val_acc: 0.6465\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7719 - acc: 0.6203 - val_loss: 0.7430 - val_acc: 0.6772\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7437 - acc: 0.6473 - val_loss: 0.7118 - val_acc: 0.7022\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7048 - acc: 0.6799 - val_loss: 0.6765 - val_acc: 0.7103\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6875 - acc: 0.6978 - val_loss: 0.6650 - val_acc: 0.7111\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6615 - acc: 0.6879 - val_loss: 0.6493 - val_acc: 0.7159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb8ad63990>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fine-tune the embedding weights - especially since the words we couldn't find in glove just have random embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6127 - acc: 0.7272 - val_loss: 0.6395 - val_acc: 0.7191\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5789 - acc: 0.7539 - val_loss: 0.6408 - val_acc: 0.7272\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5846 - acc: 0.7543 - val_loss: 0.6229 - val_acc: 0.7393\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5296 - acc: 0.7706 - val_loss: 0.6232 - val_acc: 0.7337\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5280 - acc: 0.7734 - val_loss: 0.6175 - val_acc: 0.7441\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5127 - acc: 0.7873 - val_loss: 0.6373 - val_acc: 0.7143\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4915 - acc: 0.7960 - val_loss: 0.6338 - val_acc: 0.7320\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4585 - acc: 0.8163 - val_loss: 0.6068 - val_acc: 0.7393\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4322 - acc: 0.8223 - val_loss: 0.6283 - val_acc: 0.7417\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4215 - acc: 0.8378 - val_loss: 0.6241 - val_acc: 0.7264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb8a0da910>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.optimizer.lr=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3904 - acc: 0.8461 - val_loss: 0.6197 - val_acc: 0.7401\n",
      "Epoch 2/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3812 - acc: 0.8394 - val_loss: 0.6120 - val_acc: 0.7514\n",
      "Epoch 3/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3672 - acc: 0.8600 - val_loss: 0.6053 - val_acc: 0.7571\n",
      "Epoch 4/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3674 - acc: 0.8612 - val_loss: 0.6129 - val_acc: 0.7506\n",
      "Epoch 5/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3627 - acc: 0.8473 - val_loss: 0.6123 - val_acc: 0.7482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb8bf02c50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the pretrained embeddings didn't provide any improvement..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained vectors + BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2, \n",
    "              weights=[emb], trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(128, 5, border_mode='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Dropout(0.7),\n",
    "    Dense(4, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_4 (Embedding)          (None, 1000, 100)     0           embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 1000, 100)     0           embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 1000, 128)     64128       dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 1000, 128)     0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 500, 128)      0           dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 64000)         0           maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 100)           6400100     flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNormal(None, 100)           200         dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 100)           0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 4)             404         dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 6464832\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "batch_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 2.0294 - acc: 0.3006 - val_loss: 1.3218 - val_acc: 0.3527\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.4037 - acc: 0.4195 - val_loss: 1.0957 - val_acc: 0.5182\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.1374 - acc: 0.5074 - val_loss: 1.0403 - val_acc: 0.4939\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.9541 - acc: 0.5539 - val_loss: 0.9714 - val_acc: 0.5779\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.8759 - acc: 0.6016 - val_loss: 0.9225 - val_acc: 0.6134\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7938 - acc: 0.6505 - val_loss: 0.9171 - val_acc: 0.5755\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7493 - acc: 0.6740 - val_loss: 0.8804 - val_acc: 0.6489\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7249 - acc: 0.6986 - val_loss: 0.8509 - val_acc: 0.6481\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6350 - acc: 0.7364 - val_loss: 0.8408 - val_acc: 0.5868\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6147 - acc: 0.7503 - val_loss: 0.8739 - val_acc: 0.6336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb87ae0310>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5675 - acc: 0.7698 - val_loss: 0.7829 - val_acc: 0.6529\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5324 - acc: 0.7865 - val_loss: 0.7195 - val_acc: 0.7038\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5140 - acc: 0.8072 - val_loss: 0.7830 - val_acc: 0.6295\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5166 - acc: 0.7936 - val_loss: 0.6778 - val_acc: 0.6965\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4869 - acc: 0.8123 - val_loss: 0.6580 - val_acc: 0.7135\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4773 - acc: 0.8159 - val_loss: 0.6609 - val_acc: 0.7159\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4712 - acc: 0.8147 - val_loss: 0.6684 - val_acc: 0.7119\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4312 - acc: 0.8433 - val_loss: 0.6328 - val_acc: 0.7377\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3941 - acc: 0.8604 - val_loss: 0.7846 - val_acc: 0.6610\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3851 - acc: 0.8505 - val_loss: 0.6317 - val_acc: 0.7296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb89ab1210>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_model.optimizer.lr=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3744 - acc: 0.8696 - val_loss: 0.6855 - val_acc: 0.7070\n",
      "Epoch 2/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3469 - acc: 0.8716 - val_loss: 0.6401 - val_acc: 0.7296\n",
      "Epoch 3/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3322 - acc: 0.8835 - val_loss: 0.6471 - val_acc: 0.7167\n",
      "Epoch 4/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3293 - acc: 0.8839 - val_loss: 0.7200 - val_acc: 0.6925\n",
      "Epoch 5/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3265 - acc: 0.8783 - val_loss: 0.7172 - val_acc: 0.7022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb830888d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained vectors III\n",
    "\n",
    "Let's try the model from `pretrained_word_embeddings.py (+Dropout)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deep_model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, weights=[emb], trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(5),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(5),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(35), # global max pooling\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(newsgroups.target_names), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 1000, 100)     0           embedding_input_5[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 1000, 100)     0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 996, 128)      64128       dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 996, 128)      0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 199, 128)      0           dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 195, 128)      0           convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_5 (MaxPooling1D)    (None, 39, 128)       0           dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 35, 128)       82048       maxpooling1d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 35, 128)       0           convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_6 (MaxPooling1D)    (None, 1, 128)        0           dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 128)           0           maxpooling1d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 128)           16512       flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 128)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 4)             516         dropout_15[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 245252\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 5s - loss: 1.3067 - acc: 0.3626 - val_loss: 1.1742 - val_acc: 0.4915\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.9799 - acc: 0.4831 - val_loss: 0.9304 - val_acc: 0.5174\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.8901 - acc: 0.5034 - val_loss: 0.8854 - val_acc: 0.5408\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.8379 - acc: 0.5252 - val_loss: 0.8380 - val_acc: 0.5634\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7984 - acc: 0.5519 - val_loss: 0.8056 - val_acc: 0.5932\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7781 - acc: 0.5797 - val_loss: 0.7802 - val_acc: 0.6182\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7103 - acc: 0.6485 - val_loss: 0.7086 - val_acc: 0.7062\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6369 - acc: 0.7085 - val_loss: 0.6571 - val_acc: 0.7143\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5959 - acc: 0.7423 - val_loss: 0.6236 - val_acc: 0.7433\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5701 - acc: 0.7507 - val_loss: 0.6131 - val_acc: 0.7425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb815d3f90>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5348 - acc: 0.7682 - val_loss: 0.5906 - val_acc: 0.7425\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4975 - acc: 0.7909 - val_loss: 0.5822 - val_acc: 0.7409\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4793 - acc: 0.8060 - val_loss: 0.5587 - val_acc: 0.7635\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4585 - acc: 0.8068 - val_loss: 0.5478 - val_acc: 0.7676\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4205 - acc: 0.8286 - val_loss: 0.5299 - val_acc: 0.7627\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4099 - acc: 0.8433 - val_loss: 0.5428 - val_acc: 0.7716\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3772 - acc: 0.8453 - val_loss: 0.5232 - val_acc: 0.7780\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3518 - acc: 0.8608 - val_loss: 0.5169 - val_acc: 0.7748\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3537 - acc: 0.8624 - val_loss: 0.5139 - val_acc: 0.7732\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3275 - acc: 0.8688 - val_loss: 0.5142 - val_acc: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb7ff9fd50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.optimizer.lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2940 - acc: 0.8791 - val_loss: 0.5098 - val_acc: 0.7861\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2796 - acc: 0.8891 - val_loss: 0.5084 - val_acc: 0.7764\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2991 - acc: 0.8807 - val_loss: 0.5138 - val_acc: 0.7829\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2819 - acc: 0.8819 - val_loss: 0.5162 - val_acc: 0.7732\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2503 - acc: 0.9010 - val_loss: 0.4986 - val_acc: 0.7950\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2652 - acc: 0.8871 - val_loss: 0.5539 - val_acc: 0.7748\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2645 - acc: 0.8954 - val_loss: 0.4971 - val_acc: 0.7926\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2449 - acc: 0.9046 - val_loss: 0.5250 - val_acc: 0.7837\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2580 - acc: 0.9014 - val_loss: 0.5106 - val_acc: 0.7813\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2144 - acc: 0.9252 - val_loss: 0.5163 - val_acc: 0.7918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb7ff9ff10>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than the first two pretrained embedding models and back to being competitive with the single conv layer with max pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-size CNN\n",
    "\n",
    "This is an implementation of a multi-size CNN as shown in Ben Bowles' [excellent blog post](https://quid.com/feed/how-quid-uses-deep-learning-with-small-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the functional API to create multiple conv layers of different sizes, and then concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Merge\n",
    "from keras.models import Model\n",
    "\n",
    "graph_in = Input((vocab_size, 100))\n",
    "convs = [] \n",
    "for fsz in range (3, 6): \n",
    "    x = Convolution1D(64, fsz, border_mode='same', activation='relu')(graph_in)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "out = Merge(mode='concat')(convs) \n",
    "graph = Model(graph_in, out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then replace the conv/max-pool layer in our original CNN with the concatenated conv layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi = Sequential ([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2, weights=[emb]),\n",
    "    Dropout (0.2),\n",
    "    graph,\n",
    "    Dropout (0.5),\n",
    "    Dense (100, activation='relu'),\n",
    "    Dropout (0.7),\n",
    "    Dense (len(newsgroups.target_names), activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_6 (Embedding)          (None, 1000, 100)     2000000     embedding_input_6[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 1000, 100)     0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  multiple              76992       dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 96000)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 100)           9600100     dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 100)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 4)             404         dropout_18[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 11677496\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multi.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "multi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.4489 - acc: 0.3233 - val_loss: 1.3003 - val_acc: 0.4705\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.1607 - acc: 0.4517 - val_loss: 0.9248 - val_acc: 0.5400\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.9511 - acc: 0.5093 - val_loss: 0.8174 - val_acc: 0.5569\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.8606 - acc: 0.5519 - val_loss: 0.7706 - val_acc: 0.5763\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.7963 - acc: 0.5940 - val_loss: 0.7573 - val_acc: 0.5851\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.7287 - acc: 0.6262 - val_loss: 0.7073 - val_acc: 0.6731\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.6430 - acc: 0.7042 - val_loss: 0.6469 - val_acc: 0.6893\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5849 - acc: 0.7400 - val_loss: 0.5999 - val_acc: 0.7224\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4943 - acc: 0.7885 - val_loss: 0.5494 - val_acc: 0.7651\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4353 - acc: 0.8310 - val_loss: 0.5441 - val_acc: 0.7587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb78327210>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3755 - acc: 0.8573 - val_loss: 0.5221 - val_acc: 0.7845\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3282 - acc: 0.8720 - val_loss: 0.5383 - val_acc: 0.7845\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2715 - acc: 0.8970 - val_loss: 0.5014 - val_acc: 0.7950\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2517 - acc: 0.9014 - val_loss: 0.5058 - val_acc: 0.7998\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2158 - acc: 0.9161 - val_loss: 0.5131 - val_acc: 0.8111\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.1933 - acc: 0.9272 - val_loss: 0.5480 - val_acc: 0.8015\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.1809 - acc: 0.9352 - val_loss: 0.5934 - val_acc: 0.7934\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.1690 - acc: 0.9471 - val_loss: 0.5647 - val_acc: 0.8023\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.1471 - acc: 0.9479 - val_loss: 0.5571 - val_acc: 0.8095\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.1459 - acc: 0.9507 - val_loss: 0.5508 - val_acc: 0.8095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb7cf04410>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.optimizer.lr=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1322 - acc: 0.9531 - val_loss: 0.6454 - val_acc: 0.7982\n",
      "Epoch 2/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1354 - acc: 0.9523 - val_loss: 0.6256 - val_acc: 0.8031\n",
      "Epoch 3/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1275 - acc: 0.9571 - val_loss: 0.5821 - val_acc: 0.8119\n",
      "Epoch 4/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1091 - acc: 0.9614 - val_loss: 0.5987 - val_acc: 0.8103\n",
      "Epoch 5/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1094 - acc: 0.9586 - val_loss: 0.5981 - val_acc: 0.8095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb78327310>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest deep-learning result so far! And the most comparable to the 'shallow' bag-of-words results that achieved upper-80s.\n",
    "\n",
    "Bonus: this was also the least stressful to watch train because `val_acc` (generally) continued to rise instead of bouncing around like the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lda2vec\n",
    "\n",
    "http://nbviewer.jupyter.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb\n",
    "\n",
    "http://lda2vec.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install `lda2vec` and accompanying Python module\n",
    "\n",
    "1. Download `setup.py`, `requirements.txt`, and the `lda2vec/` folder from https://github.com/cemoody/lda2vec (I used `wget`)\n",
    "2. Run `python setup.py install`\n",
    "3. To avoid [this error](https://github.com/explosion/spaCy/issues/855), re-installed Spacy with `conda install spacy -c conda-forge`\n",
    "4. To [enable CUDA support for `chainer`](https://github.com/chainer/chainer#installation), run `pip install cupy`\n",
    "\n",
    "Also: `conda install seaborn` for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate preprocessed data files\n",
    "\n",
    "_Because `lda2vec` is not fully polished, there are a few steps beyond just running `preprocess.py`_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download `GoogleNews-vectors-negative300.bin.gz` (1.53GB) and unzip it:\n",
    "\n",
    "    wget -c https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
    "    gzip -d GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `pip install pyxdameraulevenshtein` (to get access to `damerau_levenshtein_distance_ndarray`\\* in `corpus.py`)\n",
    "\n",
    "\\* Had to replace `damerau_levenshtein_distance_withNPArray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `gensim` (we'll be using the `gensim.models.KeyedVectors` module)\\*.\n",
    "\n",
    "\\* Note that the `lda2vec` module's [`corpus.py`](https://github.com/cemoody/lda2vec/blob/master/lda2vec/corpus.py) suggests it provides an option to `use_spacy` to load in word vectors, but this appears broken. Only option is `gensim` at the moment. `corpus.py` must also be modified from using the `gensim.models.word2vec` import to `gensim.models.KeyedVectors`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run either the code block below, or [preprocess.py](https://raw.githubusercontent.com/cemoody/lda2vec/master/examples/twenty_newsgroups/data/preprocess.py) in `examples/twenty_newsgroups/data` to generate the `20_newsgroup` data that `lda2vec` will run on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!python data/preprocess.py\n",
    "# from https://raw.githubusercontent.com/cemoody/lda2vec/master/examples/twenty_newsgroups/data/preprocess.py\n",
    "\n",
    "# Author: Chris Moody <chrisemoody@gmail.com>\n",
    "# License: MIT\n",
    "\n",
    "# This simple example loads the newsgroups data from sklearn\n",
    "# and train an LDA-like model on it\n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "\n",
    "from lda2vec import preprocess, Corpus\n",
    "\n",
    "# Fetch data\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "category_subset = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    'comp.os.ms-windows.misc',\n",
    "    'soc.religion.christian',\n",
    "]\n",
    "texts = fetch_20newsgroups(subset='all', categories=category_subset, remove=remove).data\n",
    "# Remove tokens with these substrings\n",
    "bad = set([\"ax>\", '`@(\"', '---', '===', '^^^'])\n",
    "\n",
    "def clean(line):\n",
    "    return ' '.join(w for w in line.split() if not any(t in w for t in bad))\n",
    "\n",
    "# Preprocess data\n",
    "max_length = 10000   # Limit of 10k words per document\n",
    "# Convert to unicode (spaCy only works with unicode)\n",
    "texts = [unicode(clean(d)) for d in texts]\n",
    "tokens, vocab = preprocess.tokenize(texts, max_length, merge=False,\n",
    "                                    n_threads=4)\n",
    "corpus = Corpus()\n",
    "# Make a ranked list of rare vs frequent words\n",
    "corpus.update_word_count(tokens)\n",
    "corpus.finalize()\n",
    "# The tokenization uses spaCy indices, and so may have gaps\n",
    "# between indices for words that aren't present in our dataset.\n",
    "# This builds a new compact index\n",
    "compact = corpus.to_compact(tokens)\n",
    "# Remove extremely rare words\n",
    "pruned = corpus.filter_count(compact, min_count=30)\n",
    "# Convert the compactified arrays into bag of words arrays\n",
    "bow = corpus.compact_to_bow(pruned)\n",
    "# Words tend to have power law frequency, so selectively\n",
    "# downsample the most prevalent words\n",
    "clean = corpus.subsample_frequent(pruned)\n",
    "# Now flatten a 2D array of document per row and word position\n",
    "# per column to a 1D array of words. This will also remove skips\n",
    "# and OoV words\n",
    "doc_ids = np.arange(pruned.shape[0])\n",
    "flattened, (doc_ids,) = corpus.compact_to_flat(pruned, doc_ids)\n",
    "assert flattened.min() >= 0\n",
    "# Fill in the pretrained word vectors\n",
    "n_dim = 300\n",
    "fn_wordvc = 'data/GoogleNews-vectors-negative300.bin'\n",
    "vectors, s, f = corpus.compact_word_vectors(vocab, filename=fn_wordvc)\n",
    "# Save all of the preprocessed files\n",
    "pickle.dump(vocab, open('vocab.pkl', 'w'))\n",
    "pickle.dump(corpus, open('corpus.pkl', 'w'))\n",
    "np.save(\"flattened\", flattened)\n",
    "np.save(\"doc_ids\", doc_ids)\n",
    "np.save(\"pruned\", pruned)\n",
    "np.save(\"bow\", bow)\n",
    "np.save(\"vectors\", vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: the above printing mappings are from `corpus.py`:\n",
    "\n",
    "    print compact, word, ' --> ', choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run [`lda2vec_run.py`](https://github.com/cemoody/lda2vec/raw/master/examples/twenty_newsgroups/lda2vec/lda2vec_run.py) in `examples/twenty_newsgroups/lda2vec` directory to generate `topics.pyldavis.npz` that contains the topic-to-word probabilities and frequencies. What's left is to visualize and label each topic from the it's prevalent words.\n",
    "\n",
    "_Note_: make sure you've downloaded `lda2vec_model.py` beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python lda2vec/lda2vec_run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "^ `lda2vec_run.py` doesn't seem to be working right... so let's download the expected output of this script from GitHub and move on: [`topics.pyldavis.npz`](https://github.com/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/topics.pyldavis.npz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the saved model topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `pyLDAvis` with `pip install git+https://github.com/bmabey/pyLDAvis.git@master#egg=pyLDAvis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npz = np.load(open('topics.pyldavis.npz', 'r'))\n",
    "dat = {k: v for (k, v) in npz.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat['vocab'] = dat['vocab'].tolist()\n",
    "#dat['term_frequency'] = dat['term_frequency'] * 1.0 / dat['term_frequency'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "topic_to_topwords = {}\n",
    "for j, topic_to_word in enumerate(dat['topic_term_dists']):\n",
    "    top = np.argsort(topic_to_word)[::-1][:top_n]\n",
    "    msg = 'Topic %i '  % j\n",
    "    top_words = [dat['vocab'][i].strip()[:35] for i in top]\n",
    "    msg += ' '.join(top_words)\n",
    "    print msg\n",
    "    topic_to_topwords[j] = top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual document topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "remove=('headers', 'footers', 'quotes')\n",
    "texts = fetch_20newsgroups(subset='train', remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print texts.data[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print texts.target_names[texts.target[51]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msg = \"{weight:02d}% in topic {topic_id:02d} which has top words {text:s}\"\n",
    "for topic_id, weight in enumerate(dat['doc_topic_dists'][51]):\n",
    "    if weight > 0.01:\n",
    "        text = ', '.join(topic_to_topwords[topic_id])\n",
    "        print msg.format(topic_id=topic_id, weight=int(weight * 100.0), text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
