{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 20 newsgroups topic analysis\n",
    "\n",
    "Instead of repeating the IMDB sentiment analysis from the lesson (because frankly, I'm a little bored with sentiment analysis), I will attempt to apply a similar approach to deep-learning NLP classification to a dataset a coworker has recently been messing around with in `scikit-learn`: `sklearn.datasets.fetch_20newsgroups`.\n",
    "\n",
    "http://people.csail.mit.edu/jrennie/20Newsgroups/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "LESSON_HOME_DIR = current_dir + '/'\n",
    "DATA_HOME_DIR = LESSON_HOME_DIR + 'data/'\n",
    "\n",
    "DATASET_DIR = DATA_HOME_DIR + '20_newsgroup/'\n",
    "MODEL_DIR = DATASET_DIR + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(DATASET_DIR)\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "category_subset = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    'comp.os.ms-windows.misc',\n",
    "    'soc.religion.christian',\n",
    "]\n",
    "\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset = 'all',\n",
    "    categories = category_subset,\n",
    "    shuffle = True,\n",
    "    remove = ('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'soc.religion.christian']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target_names` are as requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3754,), (3754,), 3754)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.filenames.shape, newsgroups.target.shape, len(newsgroups.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras implements `get_word_index()` for the IMDB dataset, which returns an dictionary of word->index derived from a json file hosted on Amazon S3.\n",
    "\n",
    "It seems bizarre to me to host this when you can easily create it on-demand... anyway, sklearn doesn't provide this. So let's create our own index with `keras.preprocessing.text.Tokenizer` (https://keras.io/preprocessing/text/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.text\n",
    "import string\n",
    "\n",
    "# Workaround to add \"Unicode support for keras.preprocessing.text\"\n",
    "# (https://github.com/fchollet/keras/issues/1072#issuecomment-295470970)\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = string.maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "vocab_size = 20000\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=vocab_size)\n",
    "tokenizer.fit_on_texts(newsgroups.data) # builds the word index\n",
    "sequences = tokenizer.texts_to_sequences(newsgroups.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72905"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse the `word_index` with `idx2word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in word_index.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first review, both as a list of indices and as text reconstructed from the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24, 2, 60, 566, 52, 20, 4829, 3, 389, 2, 3000, 1339, 2, 155, 386, 84, 901, 76, 4, 115, 24, 2, 88, 566, 76, 92, 402, 3, 525, 12351, 101, 2, 155, 385, 6, 1685, 2454, 236, 93, 182, 118, 1350, 335, 7, 108, 5725, 2764, 6, 3000, 8981, 20, 396, 3, 118, 127, 2454, 6, 158, 182, 90, 4499, 14, 129, 11, 2274, 81, 4808, 234, 219, 92, 23, 10264, 5605, 6, 720, 10, 3000, 61, 783, 5464, 8, 5725, 7, 1736, 3, 239, 3, 1464, 55, 2, 579, 5464, 214, 701, 45, 91, 23, 2, 1802, 4, 11819, 5, 1464, 10, 2, 2694, 74, 318, 10232, 129, 386, 436, 5, 10837, 24, 11, 30, 3, 102, 1641, 11, 114, 332, 8, 2, 1598, 5, 858, 537, 9, 11, 1237, 96, 386, 95, 17, 23, 3, 952, 26, 8, 9, 15584, 121, 23, 219, 9951, 9845, 61, 2104, 95, 96, 5725, 11, 8, 5, 2828, 3, 2501, 197, 4, 127, 863, 720, 200, 102, 337, 127, 1576, 1021, 93, 15, 495, 2, 2157, 4, 94, 396, 3, 5777, 127, 9605, 720, 182, 118, 614, 2221, 60, 261, 3, 583, 8, 9, 135, 2, 154, 1464, 8, 210, 1464'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(map(str, sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'on'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"on the one hand there are advantages to having the liturgy stay the same john has described some of these on the other hand some people seem to start tuning out the same old and pay attention better when things get changed around i think innovative priests and liturgy committees are trying to get our attention and make things more meaningful for us it drives me crazy too different people have differing preferences and needs in liturgy my local parish is innovative i prefer to go to mass at the next parish over sometimes we don't have the option of attending a mass in the style which best suits us john put a smiley on it but to just offer it up probably is the solution a related issue that it sounds like john does not have to deal with is that spouses may have different liturgical tastes my husband does like innovative it is a challenge to meet both of our spiritual needs without just going our separate ways when you include the factor of also trying to satisfy our children's needs things get pretty complicated one thing to remember is that even the most mass is still mass\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2word[o] for o in sequences[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 'soc.religion.christian')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target[0], newsgroups.target_names[newsgroups.target[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the lengths of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158791, 0, 1493.157432072456)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lens = np.array(map(len, newsgroups.data))\n",
    "(lens.max(), lens.min(), lens.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird that there are sentences with 0 sequences (words) in them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices of arrays that do NOT satisfy np.nonzero\n",
    "nonzero_indices = np.unique(np.nonzero(sequences)[0])\n",
    "zero_indices = set(range(len(sequences))).difference(nonzero_indices)\n",
    "len(zero_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 101 sentences with no words. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], 'alt.atheism')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[64], newsgroups.target_names[newsgroups.target[64]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad (with zero) or truncate each sentence to make consistent length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "seq_len = 1000\n",
    "\n",
    "data = sequence.pad_sequences(sequences, maxlen=seq_len, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     8,   210,  1464],\n",
       "       [    0,     0,     0, ...,  3162,     8,    11],\n",
       "       [    0,     0,     0, ...,     2,   318,  1142],\n",
       "       ..., \n",
       "       [    0,     0,     0, ...,    47,     7,   740],\n",
       "       [ 1070,    11,     8, ...,  2565,   356,   129],\n",
       "       [    0,     0,     0, ..., 16529,   364,  8254]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's turn the labels into categorical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "newsgroups.target = to_categorical(np.asarray(newsgroups.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3754, 1000), (3754, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, newsgroups.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, newsgroups.target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2515, 1000), (1239, 1000), (2515, 4), (1239, 4))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single hidden layer NN\n",
    "\n",
    "The simplest model that tends to give reasonable results is a single hidden layer net. So let's try that. Note that we can't expect to get any useful results by feeding word ids directly into a neural net - so instead we use an embedding to replace them with a vector of 32 (initially random) floats for each word in the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# input_length => 1500-word reviews, 32 floats per word\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 32, input_length=seq_len),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(len(newsgroups.target_names), activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 1000, 32)      640000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 32000)         0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           3200100     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4)             404         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3840504\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.4231 - acc: 0.2692 - val_loss: 1.3441 - val_acc: 0.3430\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.3207 - acc: 0.3340 - val_loss: 1.2871 - val_acc: 0.4092\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.2117 - acc: 0.4203 - val_loss: 1.0628 - val_acc: 0.5214\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.8870 - acc: 0.5730 - val_loss: 0.7685 - val_acc: 0.6207\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.5728 - acc: 0.7670 - val_loss: 0.7013 - val_acc: 0.6618\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.3622 - acc: 0.8823 - val_loss: 0.6265 - val_acc: 0.7094\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.2230 - acc: 0.9427 - val_loss: 0.6085 - val_acc: 0.7320\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.1432 - acc: 0.9674 - val_loss: 0.5946 - val_acc: 0.7328\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.1132 - acc: 0.9722 - val_loss: 0.6194 - val_acc: 0.7232\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.0906 - acc: 0.9753 - val_loss: 0.6230 - val_acc: 0.7393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe67cbf1f10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a mid-70s validation accuracy.. Good? Bad?\n",
    "\n",
    "Here are some accuracies [from an official `sklearn` example](http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html) that classifies documents by topics using a bag-of-words approach:\n",
    "\n",
    "```\n",
    "[('RidgeClassifier', 0.89726533628972649),\n",
    " ('Perceptron', 0.88543976348854403),\n",
    " ('PassiveAggressiveClassifier', 0.90613451589061345),\n",
    " ('KNeighborsClassifier', 0.85809312638580926),\n",
    " ('RandomForestClassifier', 0.83813747228381374),\n",
    " ('LinearSVC', 0.90022172949002222),\n",
    " ('SGDClassifier', 0.90096082779009612),\n",
    " ('LinearSVC', 0.87287509238728755),\n",
    " ('SGDClassifier', 0.88543976348854403),\n",
    " ('SGDClassifier', 0.89874353288987441),\n",
    " ('NearestCentroid', 0.85513673318551364),\n",
    " ('MultinomialNB', 0.90022172949002222),\n",
    " ('BernoulliNB', 0.88396156688839611),\n",
    " ('Pipeline', 0.8810051736881005)]\n",
    " \n",
    " mean: 0.88311688311688319\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, not a good result in comparison with much simpler approaches. Training accuracy is high, but testing accuracy is much poorer.\n",
    "\n",
    "As a sanity check, I also ran code from [`pretrained_word_embeddings.py`](https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py) (from Keras's examples repository) which also runs against `20_newsgroups` (not the `sklearn` version though), and it was able to achieve:\n",
    "\n",
    "    loss: 0.3784 - acc: 0.8734 - val_loss: 0.9177 - val_acc: 0.7257\n",
    "after 10 epochs - again, not as accurate as the 'shallow', bag-of-words models - but comparable to the results I'm receiving here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single conv layer with max pooling\n",
    "\n",
    "A CNN is likely to work better, since it's designed to take advantage of ordered data. We'll need to use a 1D CNN, since a sequence of words is 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "conv1 = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2),\n",
    "    Dropout(0.4),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    MaxPooling1D(5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(len(newsgroups.target_names), activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 1000, 100)     2000000     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1000, 100)     0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 996, 128)      64128       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 996, 128)      0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 199, 128)      0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25472)         0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           3260544     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 128)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4)             516         dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5325188\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "conv1.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "conv1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010000000474974513"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.optimizer.lr.get_value().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.3843 - acc: 0.3097 - val_loss: 1.3530 - val_acc: 0.3672\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.3072 - acc: 0.3634 - val_loss: 1.3008 - val_acc: 0.3995\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.1637 - acc: 0.4163 - val_loss: 1.0546 - val_acc: 0.5044\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.8981 - acc: 0.5507 - val_loss: 0.8433 - val_acc: 0.6086\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6943 - acc: 0.6791 - val_loss: 0.7239 - val_acc: 0.6844\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5465 - acc: 0.7678 - val_loss: 0.6518 - val_acc: 0.7264\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3971 - acc: 0.8457 - val_loss: 0.5879 - val_acc: 0.7417\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3175 - acc: 0.8779 - val_loss: 0.5782 - val_acc: 0.7595\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2600 - acc: 0.9006 - val_loss: 0.5700 - val_acc: 0.7554\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.2275 - acc: 0.9101 - val_loss: 0.5740 - val_acc: 0.7651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe672a63c10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/4\n",
      "2515/2515 [==============================] - 4s - loss: 0.2226 - acc: 0.9181 - val_loss: 0.5544 - val_acc: 0.7676\n",
      "Epoch 2/4\n",
      "2515/2515 [==============================] - 4s - loss: 0.1712 - acc: 0.9308 - val_loss: 0.6017 - val_acc: 0.7797\n",
      "Epoch 3/4\n",
      "2515/2515 [==============================] - 4s - loss: 0.1701 - acc: 0.9352 - val_loss: 0.6385 - val_acc: 0.7643\n",
      "Epoch 4/4\n",
      "2515/2515 [==============================] - 4s - loss: 0.1332 - acc: 0.9503 - val_loss: 0.6191 - val_acc: 0.7772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe677605550>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 4s - loss: 0.1232 - acc: 0.9507 - val_loss: 0.6244 - val_acc: 0.7772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe677605850>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good improvement over the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pre-trained vectors\n",
    "\n",
    "You may want to look at wordvectors.ipynb before moving on.\n",
    "\n",
    "In this section, we replicate the previous CNN, but using pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "def get_glove_dataset(dataset):\n",
    "    \"\"\"Download the requested glove dataset from files.fast.ai\n",
    "    and return a location that can be passed to load_vectors.\n",
    "    \"\"\"\n",
    "    # see wordvectors.ipynb for info on how these files were\n",
    "    # generated from the original glove data.\n",
    "    md5sums = {'6B.50d': '8e1557d1228decbda7db6dfd81cd9909',\n",
    "               '6B.100d': 'c92dbbeacde2b0384a43014885a60b2c',\n",
    "               '6B.200d': 'af271b46c04b0b2e41a84d8cd806178d',\n",
    "               '6B.300d': '30290210376887dcc6d0a5a6374d8255'}\n",
    "    glove_path = os.path.abspath('data/glove/results')\n",
    "    %mkdir -p $glove_path\n",
    "    return get_file(dataset,\n",
    "                    'http://files.fast.ai/models/glove/' + dataset + '.tgz',\n",
    "                    cache_subdir=glove_path,\n",
    "                    md5_hash=md5sums.get(dataset, None),\n",
    "                    untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import load_array\n",
    "import pickle\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untaring file...\n"
     ]
    }
   ],
   "source": [
    "vecs, words, wordidx = load_vectors(get_glove_dataset('6B.100d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glove word ids and imdb word ids use different indexes. So we create a simple function that creates an embedding matrix using the indexes from imdb, and the embeddings from glove (where they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from numpy.random import normal\n",
    "\n",
    "def create_emb():\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "\n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word and word in wordidx:\n",
    "            src_idx = wordidx[word]\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb_model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2, \n",
    "              weights=[emb], trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(128, 5, border_mode='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(4, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: I started seeing lines like `4s - loss: nan - acc: 0.6783 - val_loss: nan - val_acc: 0.2131` where in the previous epoch, `val_acc` was twice that amount. A [quick search on the forums](http://forums.fast.ai/t/why-are-my-losses-nan/2931/2) surfaced this explanation:\n",
    "\n",
    "    \"There is one thing that doesn't look quite right: the final activation is not compatible with that loss function. Categorical cross-entropy expects a 'softmax' activation in the final layer, not 'sigmoid'. Consider changing that to see what happens.\"\n",
    "    \n",
    "**Categorical cross-entropy expects a `softmax` activation in the final layer, not `sigmoid`.** So I switched to `softmax`... I don't recall ever learning this information, however. Should ponder why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 1000, 100)     0           embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1000, 100)     0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 1000, 128)     64128       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 1000, 128)     0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 500, 128)      0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 64000)         0           maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 100)           6400100     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 100)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 4)             404         dropout_7[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 6464632\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.4214 - acc: 0.3201 - val_loss: 1.2590 - val_acc: 0.4229\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.1354 - acc: 0.4382 - val_loss: 0.9398 - val_acc: 0.5117\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.9672 - acc: 0.5121 - val_loss: 0.8642 - val_acc: 0.5440\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.9053 - acc: 0.5229 - val_loss: 0.8178 - val_acc: 0.6013\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.8213 - acc: 0.5849 - val_loss: 0.7458 - val_acc: 0.6489\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7574 - acc: 0.6326 - val_loss: 0.6981 - val_acc: 0.6868\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7315 - acc: 0.6569 - val_loss: 0.6768 - val_acc: 0.6885\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7101 - acc: 0.6755 - val_loss: 0.6682 - val_acc: 0.6780\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6528 - acc: 0.7010 - val_loss: 0.6458 - val_acc: 0.7232\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6361 - acc: 0.7177 - val_loss: 0.6305 - val_acc: 0.7328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe652fd9610>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fine-tune the embedding weights - especially since the words we couldn't find in glove just have random embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6001 - acc: 0.7380 - val_loss: 0.6175 - val_acc: 0.7401\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5669 - acc: 0.7626 - val_loss: 0.5957 - val_acc: 0.7385\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5732 - acc: 0.7487 - val_loss: 0.6030 - val_acc: 0.7401\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5238 - acc: 0.7722 - val_loss: 0.6210 - val_acc: 0.7022\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5008 - acc: 0.7777 - val_loss: 0.5928 - val_acc: 0.7345\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5049 - acc: 0.7873 - val_loss: 0.5989 - val_acc: 0.7425\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4636 - acc: 0.8060 - val_loss: 0.5808 - val_acc: 0.7506\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4473 - acc: 0.8143 - val_loss: 0.5895 - val_acc: 0.7506\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4071 - acc: 0.8425 - val_loss: 0.6003 - val_acc: 0.7369\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3818 - acc: 0.8322 - val_loss: 0.6003 - val_acc: 0.7393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe652fd9850>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.optimizer.lr=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3964 - acc: 0.8330 - val_loss: 0.5867 - val_acc: 0.7546\n",
      "Epoch 2/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3622 - acc: 0.8497 - val_loss: 0.5900 - val_acc: 0.7554\n",
      "Epoch 3/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3425 - acc: 0.8592 - val_loss: 0.6120 - val_acc: 0.7377\n",
      "Epoch 4/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3464 - acc: 0.8624 - val_loss: 0.5924 - val_acc: 0.7490\n",
      "Epoch 5/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3467 - acc: 0.8660 - val_loss: 0.6055 - val_acc: 0.7458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe652fd9710>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the pretrained embeddings didn't provide any improvement..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained vectors + BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2, \n",
    "              weights=[emb], trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(128, 5, border_mode='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Dropout(0.7),\n",
    "    Dense(4, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_4 (Embedding)          (None, 1000, 100)     0           embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 1000, 100)     0           embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 1000, 128)     64128       dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 1000, 128)     0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 500, 128)      0           dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 64000)         0           maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 100)           6400100     flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNormal(None, 100)           200         dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 100)           0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 4)             404         dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 6464832\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "batch_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 2.0254 - acc: 0.2978 - val_loss: 1.4497 - val_acc: 0.3656\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.3942 - acc: 0.4366 - val_loss: 1.1038 - val_acc: 0.4366\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 1.1187 - acc: 0.4926 - val_loss: 1.0629 - val_acc: 0.5044\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.9667 - acc: 0.5614 - val_loss: 1.1015 - val_acc: 0.4334\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.8788 - acc: 0.6143 - val_loss: 1.0362 - val_acc: 0.5004\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7718 - acc: 0.6573 - val_loss: 0.9625 - val_acc: 0.5997\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.7412 - acc: 0.6998 - val_loss: 0.9523 - val_acc: 0.6094\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6608 - acc: 0.7177 - val_loss: 0.9338 - val_acc: 0.5868\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6255 - acc: 0.7419 - val_loss: 0.8902 - val_acc: 0.6336\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.6163 - acc: 0.7475 - val_loss: 0.8099 - val_acc: 0.6659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe64becef10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5179 - acc: 0.7801 - val_loss: 0.8154 - val_acc: 0.7030\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.5063 - acc: 0.8000 - val_loss: 0.7792 - val_acc: 0.6868\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4787 - acc: 0.8099 - val_loss: 0.7142 - val_acc: 0.7046\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4414 - acc: 0.8247 - val_loss: 0.6580 - val_acc: 0.7458\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.4186 - acc: 0.8266 - val_loss: 0.6574 - val_acc: 0.7458\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3753 - acc: 0.8545 - val_loss: 0.6745 - val_acc: 0.7304\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3674 - acc: 0.8684 - val_loss: 0.6755 - val_acc: 0.7070\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3274 - acc: 0.8740 - val_loss: 0.6335 - val_acc: 0.7490\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3278 - acc: 0.8847 - val_loss: 0.6393 - val_acc: 0.7345\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 4s - loss: 0.3093 - acc: 0.8811 - val_loss: 0.6001 - val_acc: 0.7393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe64f4a55d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_model.optimizer.lr=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.3023 - acc: 0.8823 - val_loss: 0.6212 - val_acc: 0.7337\n",
      "Epoch 2/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.2886 - acc: 0.8915 - val_loss: 0.6952 - val_acc: 0.7006\n",
      "Epoch 3/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.2842 - acc: 0.8938 - val_loss: 0.6426 - val_acc: 0.7320\n",
      "Epoch 4/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.2693 - acc: 0.8918 - val_loss: 0.6414 - val_acc: 0.7312\n",
      "Epoch 5/5\n",
      "2515/2515 [==============================] - 4s - loss: 0.2907 - acc: 0.8843 - val_loss: 0.6604 - val_acc: 0.7304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe65274e910>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained vectors III\n",
    "\n",
    "Let's try the model from `pretrained_word_embeddings.py (+Dropout)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deep_model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, weights=[emb], trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(5),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(5),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(35), # global max pooling\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(newsgroups.target_names), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 1000, 100)     0           embedding_input_5[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 1000, 100)     0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 996, 128)      64128       dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 996, 128)      0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 199, 128)      0           dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 195, 128)      82048       maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 195, 128)      0           convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_5 (MaxPooling1D)    (None, 39, 128)       0           dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 35, 128)       82048       maxpooling1d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 35, 128)       0           convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_6 (MaxPooling1D)    (None, 1, 128)        0           dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 128)           0           maxpooling1d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 128)           16512       flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 128)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 4)             516         dropout_15[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 245252\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 5s - loss: 1.2805 - acc: 0.3718 - val_loss: 1.1005 - val_acc: 0.4931\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.9516 - acc: 0.4946 - val_loss: 0.9012 - val_acc: 0.5303\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.8609 - acc: 0.5185 - val_loss: 0.8549 - val_acc: 0.5545\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.8261 - acc: 0.5423 - val_loss: 0.8644 - val_acc: 0.5569\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.8127 - acc: 0.5439 - val_loss: 0.8431 - val_acc: 0.5666\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.7754 - acc: 0.5738 - val_loss: 0.7854 - val_acc: 0.5916\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.7614 - acc: 0.5936 - val_loss: 0.7971 - val_acc: 0.5843\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.7318 - acc: 0.6064 - val_loss: 0.7623 - val_acc: 0.6497\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.7043 - acc: 0.6537 - val_loss: 0.7392 - val_acc: 0.6965\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.6428 - acc: 0.7121 - val_loss: 0.6837 - val_acc: 0.7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe64892bf50>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.5894 - acc: 0.7368 - val_loss: 0.6439 - val_acc: 0.7345\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.5720 - acc: 0.7392 - val_loss: 0.6288 - val_acc: 0.7433\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.5368 - acc: 0.7594 - val_loss: 0.5995 - val_acc: 0.7522\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.5072 - acc: 0.7841 - val_loss: 0.5994 - val_acc: 0.7522\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.4631 - acc: 0.8087 - val_loss: 0.5876 - val_acc: 0.7393\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.4606 - acc: 0.8008 - val_loss: 0.5710 - val_acc: 0.7627\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.4190 - acc: 0.8215 - val_loss: 0.5977 - val_acc: 0.7538\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.4279 - acc: 0.8250 - val_loss: 0.5705 - val_acc: 0.7603\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.4269 - acc: 0.8195 - val_loss: 0.5578 - val_acc: 0.7643\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.4018 - acc: 0.8219 - val_loss: 0.5675 - val_acc: 0.7627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe64892c790>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.optimizer.lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.3839 - acc: 0.8437 - val_loss: 0.6372 - val_acc: 0.7425\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.3791 - acc: 0.8469 - val_loss: 0.5717 - val_acc: 0.7554\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.3331 - acc: 0.8652 - val_loss: 0.5673 - val_acc: 0.7667\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.2888 - acc: 0.8915 - val_loss: 0.5447 - val_acc: 0.7845\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.2993 - acc: 0.8835 - val_loss: 0.5865 - val_acc: 0.7667\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.2720 - acc: 0.9006 - val_loss: 0.5519 - val_acc: 0.7869\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.2570 - acc: 0.9018 - val_loss: 0.5496 - val_acc: 0.7902\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.2875 - acc: 0.8859 - val_loss: 0.6069 - val_acc: 0.7643\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.2407 - acc: 0.9157 - val_loss: 0.5657 - val_acc: 0.7676\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 5s - loss: 0.2331 - acc: 0.9141 - val_loss: 0.5551 - val_acc: 0.7813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe64892c850>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than the first two pretrained embedding models and back to being competitive with the single conv layer with max pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-size CNN\n",
    "\n",
    "This is an implementation of a multi-size CNN as shown in Ben Bowles' [excellent blog post](https://quid.com/feed/how-quid-uses-deep-learning-with-small-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the functional API to create multiple conv layers of different sizes, and then concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Merge\n",
    "from keras.models import Model\n",
    "\n",
    "graph_in = Input((vocab_size, 100))\n",
    "convs = [] \n",
    "for fsz in range (3, 6): \n",
    "    x = Convolution1D(64, fsz, border_mode='same', activation='relu')(graph_in)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "out = Merge(mode='concat')(convs) \n",
    "graph = Model(graph_in, out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then replace the conv/max-pool layer in our original CNN with the concatenated conv layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi = Sequential ([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2, weights=[emb]),\n",
    "    Dropout (0.2),\n",
    "    graph,\n",
    "    Dropout (0.5),\n",
    "    Dense (100, activation='relu'),\n",
    "    Dropout (0.7),\n",
    "    Dense (len(newsgroups.target_names), activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_7 (Embedding)          (None, 1000, 100)     2000000     embedding_input_7[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 1000, 100)     0           embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  multiple              76992       dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 96000)         0           model_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 100)           9600100     dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 100)           0           dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 4)             404         dropout_21[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 11677496\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multi.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "multi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.5174 - acc: 0.2982 - val_loss: 1.3660 - val_acc: 0.3414\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.2941 - acc: 0.3571 - val_loss: 1.1400 - val_acc: 0.4713\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.0877 - acc: 0.4664 - val_loss: 0.9286 - val_acc: 0.5593\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.9655 - acc: 0.5062 - val_loss: 0.8375 - val_acc: 0.5650\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.8699 - acc: 0.5364 - val_loss: 0.7965 - val_acc: 0.5722\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.8103 - acc: 0.5789 - val_loss: 0.7575 - val_acc: 0.6053\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.7717 - acc: 0.6076 - val_loss: 0.7344 - val_acc: 0.6602\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.6837 - acc: 0.6755 - val_loss: 0.6683 - val_acc: 0.6868\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.6337 - acc: 0.7050 - val_loss: 0.5966 - val_acc: 0.7304\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5575 - acc: 0.7511 - val_loss: 0.5617 - val_acc: 0.7546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe63ca95d90>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4920 - acc: 0.7917 - val_loss: 0.5570 - val_acc: 0.7627\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4411 - acc: 0.8254 - val_loss: 0.5288 - val_acc: 0.7789\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4075 - acc: 0.8294 - val_loss: 0.5321 - val_acc: 0.7845\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3489 - acc: 0.8581 - val_loss: 0.5092 - val_acc: 0.7918\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3256 - acc: 0.8799 - val_loss: 0.5326 - val_acc: 0.7950\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2921 - acc: 0.8867 - val_loss: 0.5151 - val_acc: 0.7958\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2561 - acc: 0.9046 - val_loss: 0.5485 - val_acc: 0.7998\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2361 - acc: 0.9089 - val_loss: 0.5407 - val_acc: 0.8031\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2153 - acc: 0.9177 - val_loss: 0.5340 - val_acc: 0.8095\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2106 - acc: 0.9229 - val_loss: 0.5199 - val_acc: 0.8128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe63f91a210>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.optimizer.lr=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1830 - acc: 0.9312 - val_loss: 0.5532 - val_acc: 0.8152\n",
      "Epoch 2/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1925 - acc: 0.9245 - val_loss: 0.5283 - val_acc: 0.8241\n",
      "Epoch 3/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1598 - acc: 0.9392 - val_loss: 0.5557 - val_acc: 0.8111\n",
      "Epoch 4/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1668 - acc: 0.9360 - val_loss: 0.5427 - val_acc: 0.8184\n",
      "Epoch 5/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.1511 - acc: 0.9479 - val_loss: 0.5419 - val_acc: 0.8329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe63a730dd0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest deep-learning result so far! And the most comparable to the 'shallow' bag-of-words results that achieved upper-80s.\n",
    "\n",
    "Bonus: this was also the least stressful to watch train because `val_acc` (generally) continued to rise instead of bouncing around like the other models."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
