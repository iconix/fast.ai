{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 20 newsgroups topic analysis\n",
    "\n",
    "Instead of repeating the IMDB sentiment analysis from the lesson (because frankly, I'm a little bored with sentiment analysis), I will attempt to apply a similar approach to deep-learning NLP classification to a dataset a coworker has recently been messing around with in `scikit-learn`: `sklearn.datasets.fetch_20newsgroups`.\n",
    "\n",
    "http://people.csail.mit.edu/jrennie/20Newsgroups/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "LESSON_HOME_DIR = current_dir + '/'\n",
    "DATA_HOME_DIR = LESSON_HOME_DIR + 'data/'\n",
    "\n",
    "DATASET_DIR = DATA_HOME_DIR + '20_newsgroup/'\n",
    "MODEL_DIR = DATASET_DIR + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(DATASET_DIR)\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "category_subset = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    'comp.os.ms-windows.misc',\n",
    "    'soc.religion.christian',\n",
    "]\n",
    "\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset = 'all',\n",
    "    categories = category_subset,\n",
    "    shuffle = True,\n",
    "    remove = ('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'soc.religion.christian']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target_names` are as requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3754,), (3754,), 3754)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.filenames.shape, newsgroups.target.shape, len(newsgroups.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras implements `get_word_index()` for the IMDB dataset, which returns an dictionary of word->index derived from a json file hosted on Amazon S3.\n",
    "\n",
    "It seems bizarre to me to host this when you can easily create it on-demand... anyway, sklearn doesn't provide this. So let's create our own index with `keras.preprocessing.text.Tokenizer` (https://keras.io/preprocessing/text/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.text\n",
    "import string\n",
    "\n",
    "# Workaround to add \"Unicode support for keras.preprocessing.text\"\n",
    "# (https://github.com/fchollet/keras/issues/1072#issuecomment-295470970)\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = string.maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=vocab_size)\n",
    "tokenizer.fit_on_texts(newsgroups.data) # builds the word index\n",
    "sequences = tokenizer.texts_to_sequences(newsgroups.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72905"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse the `word_index` with `idx2word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in word_index.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first review, both as a list of indices and as text reconstructed from the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24, 2, 60, 566, 52, 20, 4829, 3, 389, 2, 3000, 1339, 2, 155, 386, 84, 901, 76, 4, 115, 24, 2, 88, 566, 76, 92, 402, 3, 525, 101, 2, 155, 385, 6, 1685, 2454, 236, 93, 182, 118, 1350, 335, 7, 108, 5725, 2764, 6, 3000, 8981, 20, 396, 3, 118, 127, 2454, 6, 158, 182, 90, 4499, 14, 129, 11, 2274, 81, 4808, 234, 219, 92, 23, 5605, 6, 720, 10, 3000, 61, 783, 5464, 8, 5725, 7, 1736, 3, 239, 3, 1464, 55, 2, 579, 5464, 214, 701, 45, 91, 23, 2, 1802, 4, 5, 1464, 10, 2, 2694, 74, 318, 129, 386, 436, 5, 24, 11, 30, 3, 102, 1641, 11, 114, 332, 8, 2, 1598, 5, 858, 537, 9, 11, 1237, 96, 386, 95, 17, 23, 3, 952, 26, 8, 9, 121, 23, 219, 9951, 9845, 61, 2104, 95, 96, 5725, 11, 8, 5, 2828, 3, 2501, 197, 4, 127, 863, 720, 200, 102, 337, 127, 1576, 1021, 93, 15, 495, 2, 2157, 4, 94, 396, 3, 5777, 127, 9605, 720, 182, 118, 614, 2221, 60, 261, 3, 583, 8, 9, 135, 2, 154, 1464, 8, 210, 1464'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(map(str, sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'on'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"on the one hand there are advantages to having the liturgy stay the same john has described some of these on the other hand some people seem to start out the same old and pay attention better when things get changed around i think innovative priests and liturgy committees are trying to get our attention and make things more meaningful for us it drives me crazy too different people have preferences and needs in liturgy my local parish is innovative i prefer to go to mass at the next parish over sometimes we don't have the option of a mass in the style which best us john put a on it but to just offer it up probably is the solution a related issue that it sounds like john does not have to deal with is that may have different liturgical tastes my husband does like innovative it is a challenge to meet both of our spiritual needs without just going our separate ways when you include the factor of also trying to satisfy our children's needs things get pretty complicated one thing to remember is that even the most mass is still mass\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2word[o] for o in sequences[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 'soc.religion.christian')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target[0], newsgroups.target_names[newsgroups.target[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the lengths of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158791, 0, 1493.157432072456)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lens = np.array(map(len, newsgroups.data))\n",
    "(lens.max(), lens.min(), lens.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird that there are sentences with 0 sequences (words) in them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices of arrays that do NOT satisfy np.nonzero\n",
    "nonzero_indices = np.unique(np.nonzero(sequences)[0])\n",
    "zero_indices = set(range(len(sequences))).difference(nonzero_indices)\n",
    "len(zero_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 101 sentences with no words. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], 'alt.atheism')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[64], newsgroups.target_names[newsgroups.target[64]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad (with zero) or truncate each sentence to make consistent length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "seq_len = 1500\n",
    "\n",
    "data = sequence.pad_sequences(sequences, maxlen=seq_len, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    8,  210, 1464],\n",
       "       [   0,    0,    0, ..., 3162,    8,   11],\n",
       "       [   0,    0,    0, ...,    2,  318, 1142],\n",
       "       ..., \n",
       "       [   0,    0,    0, ...,   47,    7,  740],\n",
       "       [   0,    0,    0, ..., 2565,  356,  129],\n",
       "       [   0,    0,    0, ..., 4386,  364, 8254]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's turn the labels into categorical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "newsgroups.target = to_categorical(np.asarray(newsgroups.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3754, 1500), (3754, 4))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, newsgroups.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, newsgroups.target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2515, 1500), (1239, 1500), (2515, 4), (1239, 4))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single hidden layer NN\n",
    "\n",
    "The simplest model that tends to give reasonable results is a single hidden layer net. So let's try that. Note that we can't expect to get any useful results by feeding word ids directly into a neural net - so instead we use an embedding to replace them with a vector of 32 (initially random) floats for each word in the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# input_length => 1500-word reviews, 32 floats per word\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 32, input_length=seq_len),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(len(newsgroups.target_names), activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 1500, 32)      320000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 48000)         0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           4800100     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4)             404         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5120504\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.4638 - acc: 0.2859 - val_loss: 1.3568 - val_acc: 0.3793\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.3343 - acc: 0.3300 - val_loss: 1.2943 - val_acc: 0.3810\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.2693 - acc: 0.3972 - val_loss: 1.1935 - val_acc: 0.3987\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 0s - loss: 1.0769 - acc: 0.4692 - val_loss: 0.8652 - val_acc: 0.5408\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.8102 - acc: 0.5797 - val_loss: 0.8050 - val_acc: 0.5803\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.6363 - acc: 0.7117 - val_loss: 0.7221 - val_acc: 0.6513\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.4212 - acc: 0.8370 - val_loss: 0.6487 - val_acc: 0.7296\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.2489 - acc: 0.9221 - val_loss: 0.6461 - val_acc: 0.7086\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.1689 - acc: 0.9551 - val_loss: 0.6362 - val_acc: 0.7401\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 0s - loss: 0.1250 - acc: 0.9670 - val_loss: 0.6287 - val_acc: 0.7409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb7401eb10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a mid-70s validation accuracy.. Good? Bad?\n",
    "\n",
    "Here are some accuracies [from an official `sklearn` example](http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html) that classifies documents by topics using a bag-of-words approach:\n",
    "\n",
    "```\n",
    "[('RidgeClassifier', 0.89726533628972649),\n",
    " ('Perceptron', 0.88543976348854403),\n",
    " ('PassiveAggressiveClassifier', 0.90613451589061345),\n",
    " ('KNeighborsClassifier', 0.85809312638580926),\n",
    " ('RandomForestClassifier', 0.83813747228381374),\n",
    " ('LinearSVC', 0.90022172949002222),\n",
    " ('SGDClassifier', 0.90096082779009612),\n",
    " ('LinearSVC', 0.87287509238728755),\n",
    " ('SGDClassifier', 0.88543976348854403),\n",
    " ('SGDClassifier', 0.89874353288987441),\n",
    " ('NearestCentroid', 0.85513673318551364),\n",
    " ('MultinomialNB', 0.90022172949002222),\n",
    " ('BernoulliNB', 0.88396156688839611),\n",
    " ('Pipeline', 0.8810051736881005)]\n",
    " \n",
    " mean: 0.88311688311688319\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, not a good result in comparison with much simpler approaches. Training accuracy is high, but testing accuracy is much poorer.\n",
    "\n",
    "As a sanity check, I also ran code from [`pretrained_word_embeddings.py`](https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py) (from Keras's examples repository) which also runs against `20_newsgroups` (not the `sklearn` version though), and it was able to achieve:\n",
    "\n",
    "    loss: 0.3784 - acc: 0.8734 - val_loss: 0.9177 - val_acc: 0.7257\n",
    "after 10 epochs - again, not as accurate as the 'shallow', bag-of-words models - but comparable to the results I'm receiving here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single conv layer with max pooling\n",
    "\n",
    "A CNN is likely to work better, since it's designed to take advantage of ordered data. We'll need to use a 1D CNN, since a sequence of words is 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "conv1 = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2),\n",
    "    Dropout(0.4),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    MaxPooling1D(5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(len(newsgroups.target_names), activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 1500, 100)     1000000     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1500, 100)     0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 1496, 128)     64128       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 1496, 128)     0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 299, 128)      0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 38272)         0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           4898944     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 128)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4)             516         dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5963588\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "conv1.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "conv1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010000000474974513"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.optimizer.lr.get_value().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.3735 - acc: 0.3272 - val_loss: 1.3455 - val_acc: 0.4132\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.2731 - acc: 0.3817 - val_loss: 1.1711 - val_acc: 0.4576\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.0497 - acc: 0.4962 - val_loss: 0.9098 - val_acc: 0.5884\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.8262 - acc: 0.5877 - val_loss: 0.7868 - val_acc: 0.6110\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.6989 - acc: 0.6656 - val_loss: 0.7098 - val_acc: 0.7103\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5880 - acc: 0.7451 - val_loss: 0.6323 - val_acc: 0.7579\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4639 - acc: 0.8159 - val_loss: 0.5965 - val_acc: 0.7603\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4027 - acc: 0.8497 - val_loss: 0.5812 - val_acc: 0.7748\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3406 - acc: 0.8716 - val_loss: 0.5610 - val_acc: 0.7877\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2958 - acc: 0.8895 - val_loss: 0.5624 - val_acc: 0.7813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb6a5c9d90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/4\n",
      "2515/2515 [==============================] - 7s - loss: 0.2402 - acc: 0.9002 - val_loss: 0.5972 - val_acc: 0.7893\n",
      "Epoch 2/4\n",
      "2515/2515 [==============================] - 7s - loss: 0.2298 - acc: 0.9113 - val_loss: 0.5857 - val_acc: 0.7885\n",
      "Epoch 3/4\n",
      "2515/2515 [==============================] - 7s - loss: 0.2164 - acc: 0.9197 - val_loss: 0.5755 - val_acc: 0.8006\n",
      "Epoch 4/4\n",
      "2515/2515 [==============================] - 7s - loss: 0.1904 - acc: 0.9256 - val_loss: 0.6429 - val_acc: 0.7772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb6a5c9e10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 7s - loss: 0.1851 - acc: 0.9300 - val_loss: 0.6341 - val_acc: 0.7982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb6e72cdd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good improvement over the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pre-trained vectors\n",
    "\n",
    "You may want to look at wordvectors.ipynb before moving on.\n",
    "\n",
    "In this section, we replicate the previous CNN, but using pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "def get_glove_dataset(dataset):\n",
    "    \"\"\"Download the requested glove dataset from files.fast.ai\n",
    "    and return a location that can be passed to load_vectors.\n",
    "    \"\"\"\n",
    "    # see wordvectors.ipynb for info on how these files were\n",
    "    # generated from the original glove data.\n",
    "    md5sums = {'6B.50d': '8e1557d1228decbda7db6dfd81cd9909',\n",
    "               '6B.100d': 'c92dbbeacde2b0384a43014885a60b2c',\n",
    "               '6B.200d': 'af271b46c04b0b2e41a84d8cd806178d',\n",
    "               '6B.300d': '30290210376887dcc6d0a5a6374d8255'}\n",
    "    glove_path = os.path.abspath('data/glove/results')\n",
    "    %mkdir -p $glove_path\n",
    "    return get_file(dataset,\n",
    "                    'http://files.fast.ai/models/glove/' + dataset + '.tgz',\n",
    "                    cache_subdir=glove_path,\n",
    "                    md5_hash=md5sums.get(dataset, None),\n",
    "                    untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import load_array\n",
    "import pickle\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untaring file...\n"
     ]
    }
   ],
   "source": [
    "vecs, words, wordidx = load_vectors(get_glove_dataset('6B.100d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glove word ids and imdb word ids use different indexes. So we create a simple function that creates an embedding matrix using the indexes from imdb, and the embeddings from glove (where they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from numpy.random import normal\n",
    "\n",
    "def create_emb():\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "\n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word) and word in wordidx:\n",
    "            src_idx = wordidx[word]\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb_model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2, \n",
    "              weights=[emb], trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(128, 5, border_mode='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(4, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: I started seeing lines like `4s - loss: nan - acc: 0.6783 - val_loss: nan - val_acc: 0.2131` where in the previous epoch, `val_acc` was twice that amount. A [quick search on the forums](http://forums.fast.ai/t/why-are-my-losses-nan/2931/2) surfaced this explanation:\n",
    "\n",
    "    \"There is one thing that doesn't look quite right: the final activation is not compatible with that loss function. Categorical cross-entropy expects a 'softmax' activation in the final layer, not 'sigmoid'. Consider changing that to see what happens.\"\n",
    "    \n",
    "**Categorical cross-entropy expects a `softmax` activation in the final layer, not `sigmoid`.** So I switched to `softmax`... I don't recall ever learning this information, however. Should ponder why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 1500, 100)     0           embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1500, 100)     0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 1500, 128)     64128       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 1500, 128)     0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 750, 128)      0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 96000)         0           maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 100)           9600100     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 100)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 4)             404         dropout_7[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 9664632\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.4126 - acc: 0.3439 - val_loss: 1.2499 - val_acc: 0.4536\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.0897 - acc: 0.4783 - val_loss: 0.9002 - val_acc: 0.5738\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.9248 - acc: 0.5276 - val_loss: 0.8316 - val_acc: 0.5545\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.8515 - acc: 0.5738 - val_loss: 0.7945 - val_acc: 0.6312\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.7803 - acc: 0.6243 - val_loss: 0.7496 - val_acc: 0.6320\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.7431 - acc: 0.6565 - val_loss: 0.6768 - val_acc: 0.7183\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.7122 - acc: 0.6763 - val_loss: 0.7247 - val_acc: 0.6755\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.6768 - acc: 0.6851 - val_loss: 0.6701 - val_acc: 0.7191\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.6279 - acc: 0.7153 - val_loss: 0.6252 - val_acc: 0.7288\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.6299 - acc: 0.7189 - val_loss: 0.6433 - val_acc: 0.7345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb4a0e4910>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fine-tune the embedding weights - especially since the words we couldn't find in glove just have random embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5884 - acc: 0.7487 - val_loss: 0.6114 - val_acc: 0.7466\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5612 - acc: 0.7583 - val_loss: 0.5904 - val_acc: 0.7635\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5196 - acc: 0.7702 - val_loss: 0.5956 - val_acc: 0.7530\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4626 - acc: 0.8028 - val_loss: 0.5797 - val_acc: 0.7595\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4625 - acc: 0.8151 - val_loss: 0.5950 - val_acc: 0.7393\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4386 - acc: 0.8266 - val_loss: 0.6273 - val_acc: 0.7409\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4155 - acc: 0.8330 - val_loss: 0.5951 - val_acc: 0.7441\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4019 - acc: 0.8362 - val_loss: 0.5910 - val_acc: 0.7554\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4005 - acc: 0.8545 - val_loss: 0.6883 - val_acc: 0.7264\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4051 - acc: 0.8517 - val_loss: 0.6142 - val_acc: 0.7425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb4a0e4a50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model.optimizer.lr=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.3647 - acc: 0.8561 - val_loss: 0.6195 - val_acc: 0.7466\n",
      "Epoch 2/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.3441 - acc: 0.8728 - val_loss: 0.6094 - val_acc: 0.7441\n",
      "Epoch 3/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.3235 - acc: 0.8799 - val_loss: 0.6059 - val_acc: 0.7546\n",
      "Epoch 4/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.3292 - acc: 0.8783 - val_loss: 0.6116 - val_acc: 0.7522\n",
      "Epoch 5/5\n",
      "2515/2515 [==============================] - 7s - loss: 0.2912 - acc: 0.8899 - val_loss: 0.5972 - val_acc: 0.7708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb4a0e4c90>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the pretrained embeddings didn't provide any improvement..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained vectors II\n",
    "\n",
    "Let's try the model from `pretrained_word_embeddings.py (+Dropout)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, weights=[emb], trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(5),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(5),\n",
    "    Convolution1D(128, 5, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(newsgroups.target_names), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_4 (Embedding)          (None, 1500, 100)     0           embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 1500, 100)     0           embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 1496, 128)     64128       dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 1496, 128)     0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 299, 128)      0           dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 295, 128)      82048       maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 295, 128)      0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 59, 128)       0           dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 55, 128)       82048       maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 55, 128)       0           convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_5 (MaxPooling1D)    (None, 11, 128)       0           dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 1408)          0           maxpooling1d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 128)           180352      flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 128)           0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 4)             516         dropout_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 409092\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 1.2484 - acc: 0.3901 - val_loss: 1.0479 - val_acc: 0.5044\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.9616 - acc: 0.5141 - val_loss: 0.9011 - val_acc: 0.5375\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.8379 - acc: 0.5519 - val_loss: 0.8552 - val_acc: 0.5626\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.8076 - acc: 0.5404 - val_loss: 0.8240 - val_acc: 0.5666\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.7818 - acc: 0.5674 - val_loss: 0.7776 - val_acc: 0.6255\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.7555 - acc: 0.5841 - val_loss: 0.7733 - val_acc: 0.6053\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.7022 - acc: 0.6330 - val_loss: 0.6803 - val_acc: 0.7159\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.6272 - acc: 0.7018 - val_loss: 0.6446 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5827 - acc: 0.7276 - val_loss: 0.6239 - val_acc: 0.7304\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5448 - acc: 0.7491 - val_loss: 0.5809 - val_acc: 0.7563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb46a71d10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5103 - acc: 0.7622 - val_loss: 0.6136 - val_acc: 0.7441\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.5268 - acc: 0.7567 - val_loss: 0.5665 - val_acc: 0.7635\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4768 - acc: 0.7917 - val_loss: 0.5503 - val_acc: 0.7764\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4577 - acc: 0.7996 - val_loss: 0.5354 - val_acc: 0.7869\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.4267 - acc: 0.8203 - val_loss: 0.5340 - val_acc: 0.7789\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3926 - acc: 0.8322 - val_loss: 0.5500 - val_acc: 0.7797\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3678 - acc: 0.8441 - val_loss: 0.5580 - val_acc: 0.7684\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3536 - acc: 0.8533 - val_loss: 0.5461 - val_acc: 0.7708\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3464 - acc: 0.8616 - val_loss: 0.5245 - val_acc: 0.7877\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3264 - acc: 0.8624 - val_loss: 0.5955 - val_acc: 0.7546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb46a71e50>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_model.optimizer.lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3386 - acc: 0.8541 - val_loss: 0.6023 - val_acc: 0.7538\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.3042 - acc: 0.8795 - val_loss: 0.6161 - val_acc: 0.7417\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2850 - acc: 0.8851 - val_loss: 0.5044 - val_acc: 0.7998\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2668 - acc: 0.8859 - val_loss: 0.5371 - val_acc: 0.7910\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2538 - acc: 0.8998 - val_loss: 0.5208 - val_acc: 0.7942\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2028 - acc: 0.9197 - val_loss: 0.5487 - val_acc: 0.8031\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2284 - acc: 0.9085 - val_loss: 0.5271 - val_acc: 0.7934\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2096 - acc: 0.9260 - val_loss: 0.5520 - val_acc: 0.7942\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2378 - acc: 0.9097 - val_loss: 0.5683 - val_acc: 0.7837\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 7s - loss: 0.2164 - acc: 0.9217 - val_loss: 0.5161 - val_acc: 0.7998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb46a72110>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no sizeable boost, although slightly better than the first pretrained embedding model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-size CNN\n",
    "\n",
    "This is an implementation of a multi-size CNN as shown in Ben Bowles' [excellent blog post](https://quid.com/feed/how-quid-uses-deep-learning-with-small-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the functional API to create multiple conv layers of different sizes, and then concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Merge\n",
    "from keras.models import Model\n",
    "\n",
    "graph_in = Input((vocab_size, 100))\n",
    "convs = [] \n",
    "for fsz in range (3, 6): \n",
    "    x = Convolution1D(64, fsz, border_mode='same', activation='relu')(graph_in)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "out = Merge(mode='concat')(convs) \n",
    "graph = Model(graph_in, out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then replace the conv/max-pool layer in our original CNN with the concatenated conv layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi = Sequential ([\n",
    "    Embedding(vocab_size, 100, input_length=seq_len, dropout=0.2, weights=[emb]),\n",
    "    Dropout (0.2),\n",
    "    graph,\n",
    "    Dropout (0.5),\n",
    "    Dense (100, activation='relu'),\n",
    "    Dropout (0.7),\n",
    "    Dense (len(newsgroups.target_names), activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_6 (Embedding)          (None, 1500, 100)     1000000     embedding_input_6[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 1500, 100)     0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  multiple              76992       dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 144000)        0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 100)           14400100    dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 100)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 4)             404         dropout_18[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 15477496\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multi.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "multi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 11s - loss: 1.4061 - acc: 0.3380 - val_loss: 1.1329 - val_acc: 0.4980\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 11s - loss: 1.0342 - acc: 0.4771 - val_loss: 0.8710 - val_acc: 0.5658\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.8682 - acc: 0.5634 - val_loss: 0.7894 - val_acc: 0.5924\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.7957 - acc: 0.6008 - val_loss: 0.7240 - val_acc: 0.6336\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.6779 - acc: 0.6811 - val_loss: 0.6272 - val_acc: 0.7215\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.5724 - acc: 0.7332 - val_loss: 0.5782 - val_acc: 0.7724\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.4703 - acc: 0.8159 - val_loss: 0.5079 - val_acc: 0.8047\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.4130 - acc: 0.8306 - val_loss: 0.4924 - val_acc: 0.8136\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.3546 - acc: 0.8596 - val_loss: 0.4876 - val_acc: 0.8192\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.3034 - acc: 0.8724 - val_loss: 0.5096 - val_acc: 0.8192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb40102610>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2515 samples, validate on 1239 samples\n",
      "Epoch 1/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.2720 - acc: 0.9034 - val_loss: 0.4933 - val_acc: 0.8281\n",
      "Epoch 2/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.2271 - acc: 0.9165 - val_loss: 0.5325 - val_acc: 0.8208\n",
      "Epoch 3/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.2114 - acc: 0.9217 - val_loss: 0.5175 - val_acc: 0.8354\n",
      "Epoch 4/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.1730 - acc: 0.9332 - val_loss: 0.5267 - val_acc: 0.8321\n",
      "Epoch 5/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.1700 - acc: 0.9408 - val_loss: 0.5297 - val_acc: 0.8426\n",
      "Epoch 6/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.1516 - acc: 0.9451 - val_loss: 0.5547 - val_acc: 0.8386\n",
      "Epoch 7/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.1487 - acc: 0.9499 - val_loss: 0.6858 - val_acc: 0.8111\n",
      "Epoch 8/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.1484 - acc: 0.9471 - val_loss: 0.5705 - val_acc: 0.8313\n",
      "Epoch 9/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.1361 - acc: 0.9507 - val_loss: 0.5859 - val_acc: 0.8337\n",
      "Epoch 10/10\n",
      "2515/2515 [==============================] - 11s - loss: 0.1548 - acc: 0.9503 - val_loss: 0.5703 - val_acc: 0.8426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb40102d90>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest, most 'stable' (where stable means the `val_acc` generally continued to rise most of the time instead of bouncing around) results so far. And most comparable to the 'shallow' bag of words results in the upper-80s."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
