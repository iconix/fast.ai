{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setup\n",
    "\n",
    "We're going to download the collected plays of Shakespeare to use as our data.\n",
    "\n",
    "Source: http://www.gutenberg.org/cache/epub/100/pg100.txt\n",
    "\n",
    "The original source was preprocessed to remove sonnets and non-Shakesperean text added by Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = BASE_DIR + '/data/shakespeare/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = DATA_DIR + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 5291227)\n"
     ]
    }
   ],
   "source": [
    "data = DATA_DIR + 'gutenberg_shakespeare_modified.txt' # preprocessed\n",
    "\n",
    "with open(data, 'r') as f:\n",
    "    text = f.read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total chars:', 88)\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's useful to have a zero value in the dataset, e.g. for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00\\n\\r !\"&\\'(),-.0123456789:;<?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz|}\\xbb\\xbf\\xef'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map chars to indices and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\x00': 0, ' ': 3, '(': 8, ',': 10, '0': 13, '4': 17, '8': 21, '\\xbb': 85, '<': 25, '\\xbf': 86, 'D': 30, 'H': 34, 'L': 38, 'P': 42, 'T': 46, 'X': 50, '`': 56, 'd': 60, 'h': 64, 'l': 68, '\\xef': 87, 'p': 72, 't': 76, 'x': 80, '|': 83, \"'\": 7, '3': 16, '7': 20, ';': 24, '?': 26, 'C': 29, 'G': 33, 'K': 37, 'O': 41, 'S': 45, 'W': 49, '[': 53, '_': 55, 'c': 59, 'g': 63, 'k': 67, 'o': 71, 's': 75, 'w': 79, '\\n': 1, '\"': 5, '&': 6, '.': 12, '2': 15, '6': 19, ':': 23, 'B': 28, 'F': 32, 'J': 36, 'N': 40, 'R': 44, 'V': 48, 'Z': 52, 'b': 58, 'f': 62, 'j': 66, 'n': 70, 'r': 74, 'v': 78, 'z': 82, '\\r': 2, '!': 4, ')': 9, '-': 11, '1': 14, '5': 18, '9': 22, 'A': 27, 'E': 31, 'I': 35, 'M': 39, 'Q': 43, 'U': 47, 'Y': 51, ']': 54, 'a': 57, 'e': 61, 'i': 65, 'm': 69, 'q': 73, 'u': 77, 'y': 81, '}': 84}\n"
     ]
    }
   ],
   "source": [
    "print(char_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*idx* converts the Shakepearean text to character indices (based on the *char_indices* mapping above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87, 85, 86, 45, 29, 31, 40, 31, 23, 2, 1, 44, 71, 77, 75, 65, 68, 68, 71, 70, 24, 3, 42, 57, 74, 65, 75, 24, 3, 32, 68, 71, 74, 61, 70, 59, 61, 24, 3, 39, 57, 74, 75, 61, 65, 68, 68, 61, 75, 2, 1, 2, 1, 2, 1, 27, 29, 46, 3, 35, 12, 3, 45, 29, 31, 40, 31, 3, 14, 12]\n"
     ]
    }
   ],
   "source": [
    "print(idx[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xef\\xbb\\xbfSCENE:\\r\\nRousillon; Paris; Florence; Marseilles\\r\\n\\r\\n\\r\\nACT I. SCENE 1.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 char model\n",
    "\n",
    "### Create inputs\n",
    "\n",
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc=3 # num chars\n",
    "c1_dat = [idx[i] for i in xrange(0, len(idx)-1-nc, nc)]\n",
    "c2_dat = [idx[i+1] for i in xrange(0, len(idx)-1-nc, nc)]\n",
    "c3_dat = [idx[i+2] for i in xrange(0, len(idx)-1-nc, nc)]\n",
    "c4_dat = [idx[i+3] for i in xrange(0, len(idx)-1-nc, nc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0, len(idx)-1-nc, nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(c1_dat), len(c4_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Out inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x1 = np.stack(c1_dat)\n",
    "x2 = np.stack(c2_dat)\n",
    "x3 = np.stack(c3_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42 # number of latent factors (size of embedding matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create inputs and embedding outputs for each of our 3 character inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding\n",
    "from keras.layers.core import Flatten\n",
    "\n",
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name+'_in')\n",
    "    emb = Embedding(n_in, n_out, input_length=1, name=name+'_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1_in, c1_emb = embedding_input('c1', vocab_size, n_fac)\n",
    "c2_in, c2_emb = embedding_input('c2', vocab_size, n_fac)\n",
    "c3_in, c3_emb = embedding_input('c3', vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 # hyperparameter: size of hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![3char](./3char.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dense_in` is the 'green arrow' in the diagram - the layer operation from input to hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense\n",
    "\n",
    "dense_in = Dense(n_hidden, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first hidden activation is simply this function applied to the result of the embedding of the first character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_hidden = dense_in(c1_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dense_hidden` is the 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
    "\n",
    "_Note:_ unsure why the activation for this is `tanh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_hidden = Dense(n_hidden, activation='tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second and third activations sum up the previous hidden state (after applying `dense_hidden`) to the new input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import merge\n",
    "\n",
    "# merge([new input state, orange arrow from previous hidden state])\n",
    "c2_hidden = merge([dense_in(c2_emb), dense_hidden(c1_hidden)])\n",
    "c3_hidden = merge([dense_in(c3_emb), dense_hidden(c2_hidden)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dense_out` is the 'blue arrow' from our diagram - the layer operation from hidden to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third hidden state is the input to our output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c4_out = dense_out(c3_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Model([c1_in, c2_in, c3_in], c4_out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.optimizer.lr=0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save1_path = model_path + 'save1.h5'\n",
    "if not os.path.exists(save1_path):\n",
    "    model.save_weights(save1_path)\n",
    "model.load_weights(save1_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"`newaxis` is used to increase the dimension of the existing array by one more dimension, when used once\" - [source](https://stackoverflow.com/questions/29241056/the-use-of-numpy-newaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(m, inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = m.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_next(model, 'phi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_next(model, ' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_next(model, ' an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first RNN!\n",
    "\n",
    "\n",
    "### Create inputs\n",
    "\n",
    "Now let's try predicting char 9 using chars 1-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Embedding, merge\n",
    "from keras.layers.core import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc = 8 # numChars == size of our unrolled RNN\n",
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+n] for i in xrange(0, len(idx)-1-nc, nc)]\n",
    "           for n in range(nc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [idx[i+nc] for i in xrange(0, len(idx)-1-nc, nc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = [np.stack(c) for c in c_in_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (661403,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each column below is one series of 8 characters from the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([87, 23, 68, 74, 74, 57, 75, 29]),\n",
       " array([85,  2, 68, 65, 61, 74,  2, 46]),\n",
       " array([86,  1, 71, 75, 70, 75,  1,  3]),\n",
       " array([45, 44, 70, 24, 59, 61,  2, 35]),\n",
       " array([29, 71, 24,  3, 61, 65,  1, 12]),\n",
       " array([31, 77,  3, 32, 24, 68,  2,  3]),\n",
       " array([40, 75, 42, 68,  3, 68,  1, 45]),\n",
       " array([31, 65, 57, 71, 39, 61, 27, 29])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:nc] for n in range(nc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this is the next character after each sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 68, 74, 74, 57, 75, 29, 31])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:nc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name+'_in')\n",
    "    emb = Embedding(n_in, n_out, input_length=1, name=name+'_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs = [embedding_input('c'+str(n), vocab_size, n_fac) for n in range(nc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I'd suggest trying the trick I mentioned in the lesson for simple RNNs: using an identity matrix to initialize your hidden state, and use relu instead of tanh.\" - [Jeremy on forums](http://forums.fast.ai/t/purpose-of-rnns-and-theano/242/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='relu', init='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding of the first character of each sequence goes through `dense_in` to create our first hidden activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = dense_in(cs[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each successive layer, we combine the output of `dense_in` on the next character with the output of `dense_hidden` on the current hidden state to create the new hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1, nc):\n",
    "    dense = dense_in(cs[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([dense, hidden])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the final hidden state through `dense_out` gives us our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "c0 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c1 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1, 42)         3696        c0[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 1, 42)         3696        c1[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 42)            0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 256)           11008       flatten_9[0][0]                  \n",
      "                                                                   flatten_10[0][0]                 \n",
      "                                                                   flatten_11[0][0]                 \n",
      "                                                                   flatten_12[0][0]                 \n",
      "                                                                   flatten_13[0][0]                 \n",
      "                                                                   flatten_14[0][0]                 \n",
      "                                                                   flatten_15[0][0]                 \n",
      "                                                                   flatten_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "c2 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 42)            0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 256)           65792       dense_4[0][0]                    \n",
      "                                                                   merge_8[0][0]                    \n",
      "                                                                   merge_9[0][0]                    \n",
      "                                                                   merge_10[0][0]                   \n",
      "                                                                   merge_11[0][0]                   \n",
      "                                                                   merge_12[0][0]                   \n",
      "                                                                   merge_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 1, 42)         3696        c2[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "c3 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 42)            0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 256)           0           dense_4[1][0]                    \n",
      "                                                                   dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)          (None, 1, 42)         3696        c3[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "c4 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 42)            0           embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 256)           0           dense_4[2][0]                    \n",
      "                                                                   dense_5[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 1, 42)         3696        c4[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "c5 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 42)            0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 256)           0           dense_4[3][0]                    \n",
      "                                                                   dense_5[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)          (None, 1, 42)         3696        c5[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "c6 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 42)            0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_11 (Merge)                 (None, 256)           0           dense_4[4][0]                    \n",
      "                                                                   dense_5[3][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)          (None, 1, 42)         3696        c6[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "c7 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 42)            0           embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_12 (Merge)                 (None, 256)           0           dense_4[5][0]                    \n",
      "                                                                   dense_5[4][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)          (None, 1, 42)         3696        c7[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)             (None, 42)            0           embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_13 (Merge)                 (None, 256)           0           dense_4[6][0]                    \n",
      "                                                                   dense_5[5][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "merge_14 (Merge)                 (None, 256)           0           dense_4[7][0]                    \n",
      "                                                                   dense_5[6][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 88)            22616       merge_14[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 128984\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([c[0] for c in cs], out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "661403/661403 [==============================] - 89s - loss: 1.6109    \n",
      "Epoch 2/12\n",
      "168256/661403 [======>.......................] - ETA: 67s - loss: 1.5958"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-b33622d48776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(xs, y, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(m, inp):\n",
    "    arrs = [np.array(char_indices[c])[np.newaxis] for c in inp]\n",
    "    p = m.predict(arrs)\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_next(model, 'for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_next(model, 'part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_next(model, 'queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helper function for generating `k` additional words (separated by whitespace) in a starter sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_seq(m, inp, k):\n",
    "    k_count = 0\n",
    "    seq = inp\n",
    "    while k_count < k+1:\n",
    "        pc = get_next(m, inp)\n",
    "        seq += pc\n",
    "        inp = inp[1:] + pc\n",
    "        if (pc == ' '):\n",
    "            k_count += 1\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_seq(model, 'queens a', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_seq(model, 'part of ', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_seq(model, 'for thos', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model currently seems to 'fixate' on the phrase \"the some sore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(xs, y, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queens and the best with the best with the best with the '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_seq(model, 'queens a', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'part of the beat the best with the best with the best with '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_seq(model, 'part of ', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for thos mey so that she seanon the rest readond and the '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_seq(model, 'for thos', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save2_path = model_path + 'save2.h5'\n",
    "if not os.path.exists(save2_path):\n",
    "    model.save_weights(save2_path)\n",
    "model.load_weights(save2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different 'fixation' on the phrase \"the best with\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first RNN with keras!\n",
    "\n",
    "This is nearly equivalent to the RNN we built ourselves in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "n_hidden, n_fac, nc, vocab_size = (256, 42, 8, 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_11 (Embedding)         (None, 8, 42)         3696        embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "simplernn_3 (SimpleRNN)          (None, 256)           76544       embedding_11[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 88)            22616       simplernn_3[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 102856\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=nc),\n",
    "        SimpleRNN(n_hidden, activation='relu', inner_init='identity'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid `IndexError: axis 1 out of bounds [0, 1)`: http://forums.fast.ai/t/lesson-6-discussion/245/70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "661403/661403 [==============================] - 94s - loss: 1.9521    \n",
      "Epoch 2/12\n",
      "661403/661403 [==============================] - 95s - loss: 1.5977    \n",
      "Epoch 3/12\n",
      "661403/661403 [==============================] - 92s - loss: 1.5132    \n",
      "Epoch 4/12\n",
      "661403/661403 [==============================] - 91s - loss: 1.4692    \n",
      "Epoch 5/12\n",
      "661403/661403 [==============================] - 87s - loss: 1.4430    \n",
      "Epoch 6/12\n",
      "661403/661403 [==============================] - 88s - loss: 1.4235    \n",
      "Epoch 7/12\n",
      "661403/661403 [==============================] - 87s - loss: 1.4093    \n",
      "Epoch 8/12\n",
      "661403/661403 [==============================] - 91s - loss: 1.3991    \n",
      "Epoch 9/12\n",
      "661403/661403 [==============================] - 88s - loss: 1.3907    \n",
      "Epoch 10/12\n",
      "661403/661403 [==============================] - 89s - loss: 1.3837    \n",
      "Epoch 11/12\n",
      "661403/661403 [==============================] - 88s - loss: 1.3779    \n",
      "Epoch 12/12\n",
      "661403/661403 [==============================] - 87s - loss: 1.3727    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ef7feb550>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate([x[np.newaxis] for x in xs]).T, y, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_keras(m, inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p = m.predict(arrs)[0]\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_keras_seq(m, inp, k):\n",
    "    k_count = 0\n",
    "    seq = inp\n",
    "    while k_count < k+1:\n",
    "        pc = get_next_keras(m, inp)\n",
    "        seq += pc\n",
    "        inp = inp[1:] + pc\n",
    "        if (pc == ' '):\n",
    "            k_count += 1\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queens and the sent the sent the sent the sent the sent '"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keras_seq(model, 'queens a', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'part of the sent the sent the sent the sent the sent the '"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keras_seq(model, 'part of ', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for those the sent the sent the sent the sent the sent '"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keras_seq(model, 'for thos', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Fixation_: \"the sent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "661403/661403 [==============================] - 87s - loss: 1.3689    \n",
      "Epoch 2/12\n",
      "661403/661403 [==============================] - 90s - loss: 1.3651    \n",
      "Epoch 3/12\n",
      "661403/661403 [==============================] - 89s - loss: 1.3620    \n",
      "Epoch 4/12\n",
      "661403/661403 [==============================] - 87s - loss: 1.3588    \n",
      "Epoch 5/12\n",
      "661403/661403 [==============================] - 89s - loss: 1.3565    \n",
      "Epoch 6/12\n",
      "661403/661403 [==============================] - 95s - loss: 1.3541    \n",
      "Epoch 7/12\n",
      "661403/661403 [==============================] - 90s - loss: 1.3523    \n",
      "Epoch 8/12\n",
      "661403/661403 [==============================] - 87s - loss: 1.3506    \n",
      "Epoch 9/12\n",
      "661403/661403 [==============================] - 89s - loss: 1.3479    \n",
      "Epoch 10/12\n",
      "661403/661403 [==============================] - 87s - loss: 1.3474    \n",
      "Epoch 11/12\n",
      "661403/661403 [==============================] - 88s - loss: 1.3447    \n",
      "Epoch 12/12\n",
      "661403/661403 [==============================] - 87s - loss: 1.3440    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0efacf2f90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate([x[np.newaxis] for x in xs]).T, y, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queens and the serve me to the serve me to the serve '"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keras_seq(model, 'queens a', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'part of the serve me to the serve me to the serve me '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keras_seq(model, 'part of ', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for those the serve me to the serve me to the serve '"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keras_seq(model, 'for thos', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Fixation_: \"the serve me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save3_path = model_path + 'save3.h5'\n",
    "if not os.path.exists(save3_path):\n",
    "    model.save_weights(save3_path)\n",
    "model.load_weights(save3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning sequences\n",
    "\n",
    "### Create inputs\n",
    "\n",
    "To use a sequence model, we can leave our input unchanged - but we have to change our output to a sequence.\n",
    "\n",
    "Here, `c_out_dat` is identical to `c_in_dat`, but moved across 1 character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+n] for i in xrange(1, len(idx)-nc, nc)]\n",
    "            for n in range(nc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [np.stack(c) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading down each column shows one set of inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([87, 23, 68, 74, 74, 57, 75, 29]),\n",
       " array([85,  2, 68, 65, 61, 74,  2, 46]),\n",
       " array([86,  1, 71, 75, 70, 75,  1,  3]),\n",
       " array([45, 44, 70, 24, 59, 61,  2, 35]),\n",
       " array([29, 71, 24,  3, 61, 65,  1, 12]),\n",
       " array([31, 77,  3, 32, 24, 68,  2,  3]),\n",
       " array([40, 75, 42, 68,  3, 68,  1, 45]),\n",
       " array([31, 65, 57, 71, 39, 61, 27, 29])]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:nc] for n in range(nc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([85,  2, 68, 65, 61, 74,  2, 46]),\n",
       " array([86,  1, 71, 75, 70, 75,  1,  3]),\n",
       " array([45, 44, 70, 24, 59, 61,  2, 35]),\n",
       " array([29, 71, 24,  3, 61, 65,  1, 12]),\n",
       " array([31, 77,  3, 32, 24, 68,  2,  3]),\n",
       " array([40, 75, 42, 68,  3, 68,  1, 45]),\n",
       " array([31, 65, 57, 71, 39, 61, 27, 29]),\n",
       " array([23, 68, 74, 74, 57, 75, 29, 31])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ys[n][:nc] for n in range(nc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='relu', init='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax', name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to pass a vectcor of all zeros as our starting point - here's our input layers for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp1 = Input(shape=(n_fac,), name='zeros')\n",
    "hidden = dense_in(inp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs = []\n",
    "\n",
    "for i in range(nc):\n",
    "    dense = dense_in(cs[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([dense, hidden], mode='sum')\n",
    "    # every layer now has an output\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "c0 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1, 42)         3696        c0[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "zeros (InputLayer)               (None, 42)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 256)           11008       zeros[0][0]                      \n",
      "                                                                   flatten_9[0][0]                  \n",
      "                                                                   flatten_10[0][0]                 \n",
      "                                                                   flatten_11[0][0]                 \n",
      "                                                                   flatten_12[0][0]                 \n",
      "                                                                   flatten_13[0][0]                 \n",
      "                                                                   flatten_14[0][0]                 \n",
      "                                                                   flatten_15[0][0]                 \n",
      "                                                                   flatten_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 42)            0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "c1 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 256)           65792       dense_10[0][0]                   \n",
      "                                                                   merge_15[0][0]                   \n",
      "                                                                   merge_16[0][0]                   \n",
      "                                                                   merge_17[0][0]                   \n",
      "                                                                   merge_18[0][0]                   \n",
      "                                                                   merge_19[0][0]                   \n",
      "                                                                   merge_20[0][0]                   \n",
      "                                                                   merge_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 1, 42)         3696        c1[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "merge_15 (Merge)                 (None, 256)           0           dense_10[1][0]                   \n",
      "                                                                   dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 42)            0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "c2 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 1, 42)         3696        c2[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "merge_16 (Merge)                 (None, 256)           0           dense_10[2][0]                   \n",
      "                                                                   dense_11[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 42)            0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "c3 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)          (None, 1, 42)         3696        c3[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "merge_17 (Merge)                 (None, 256)           0           dense_10[3][0]                   \n",
      "                                                                   dense_11[2][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 42)            0           embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "c4 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 1, 42)         3696        c4[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "merge_18 (Merge)                 (None, 256)           0           dense_10[4][0]                   \n",
      "                                                                   dense_11[3][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 42)            0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "c5 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)          (None, 1, 42)         3696        c5[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "merge_19 (Merge)                 (None, 256)           0           dense_10[5][0]                   \n",
      "                                                                   dense_11[4][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 42)            0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "c6 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)          (None, 1, 42)         3696        c6[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "c7 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_20 (Merge)                 (None, 256)           0           dense_10[6][0]                   \n",
      "                                                                   dense_11[5][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 42)            0           embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)          (None, 1, 42)         3696        c7[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)             (None, 42)            0           embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_21 (Merge)                 (None, 256)           0           dense_10[7][0]                   \n",
      "                                                                   dense_11[6][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_22 (Merge)                 (None, 256)           0           dense_10[8][0]                   \n",
      "                                                                   dense_11[7][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 88)            22616       merge_15[0][0]                   \n",
      "                                                                   merge_16[0][0]                   \n",
      "                                                                   merge_17[0][0]                   \n",
      "                                                                   merge_18[0][0]                   \n",
      "                                                                   merge_19[0][0]                   \n",
      "                                                                   merge_20[0][0]                   \n",
      "                                                                   merge_21[0][0]                   \n",
      "                                                                   merge_22[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 128984\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([inp1] + [c[0] for c in cs], outs)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661403, 42)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.tile(np.zeros(n_fac), (len(xs[0]), 1))\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "661403/661403 [==============================] - 215s - loss: 16.4319 - output_loss_1: 2.4577 - output_loss_2: 2.2454 - output_loss_3: 2.0558 - output_loss_4: 1.9853 - output_loss_5: 1.9378 - output_loss_6: 1.9226 - output_loss_7: 1.9170 - output_loss_8: 1.9103   \n",
      "Epoch 2/12\n",
      "661403/661403 [==============================] - 219s - loss: 15.2879 - output_loss_1: 2.4150 - output_loss_2: 2.1894 - output_loss_3: 1.9444 - output_loss_4: 1.8254 - output_loss_5: 1.7530 - output_loss_6: 1.7278 - output_loss_7: 1.7187 - output_loss_8: 1.7142   \n",
      "Epoch 3/12\n",
      "661403/661403 [==============================] - 214s - loss: 15.0585 - output_loss_1: 2.4121 - output_loss_2: 2.1849 - output_loss_3: 1.9291 - output_loss_4: 1.7954 - output_loss_5: 1.7138 - output_loss_6: 1.6823 - output_loss_7: 1.6721 - output_loss_8: 1.6689   \n",
      "Epoch 4/12\n",
      "661403/661403 [==============================] - 213s - loss: 14.9454 - output_loss_1: 2.4110 - output_loss_2: 2.1823 - output_loss_3: 1.9221 - output_loss_4: 1.7807 - output_loss_5: 1.6941 - output_loss_6: 1.6606 - output_loss_7: 1.6493 - output_loss_8: 1.6454   \n",
      "Epoch 5/12\n",
      "661403/661403 [==============================] - 213s - loss: 14.8768 - output_loss_1: 2.4100 - output_loss_2: 2.1806 - output_loss_3: 1.9176 - output_loss_4: 1.7719 - output_loss_5: 1.6827 - output_loss_6: 1.6469 - output_loss_7: 1.6356 - output_loss_8: 1.6315   \n",
      "Epoch 6/12\n",
      "661403/661403 [==============================] - 218s - loss: 14.8287 - output_loss_1: 2.4093 - output_loss_2: 2.1798 - output_loss_3: 1.9150 - output_loss_4: 1.7658 - output_loss_5: 1.6743 - output_loss_6: 1.6375 - output_loss_7: 1.6256 - output_loss_8: 1.6215   \n",
      "Epoch 7/12\n",
      "661403/661403 [==============================] - 221s - loss: 14.7918 - output_loss_1: 2.4088 - output_loss_2: 2.1790 - output_loss_3: 1.9123 - output_loss_4: 1.7608 - output_loss_5: 1.6683 - output_loss_6: 1.6309 - output_loss_7: 1.6179 - output_loss_8: 1.6137   \n",
      "Epoch 8/12\n",
      "661403/661403 [==============================] - 222s - loss: 14.7637 - output_loss_1: 2.4088 - output_loss_2: 2.1778 - output_loss_3: 1.9108 - output_loss_4: 1.7574 - output_loss_5: 1.6631 - output_loss_6: 1.6247 - output_loss_7: 1.6125 - output_loss_8: 1.6085   \n",
      "Epoch 9/12\n",
      "661403/661403 [==============================] - 216s - loss: 14.7403 - output_loss_1: 2.4082 - output_loss_2: 2.1773 - output_loss_3: 1.9092 - output_loss_4: 1.7547 - output_loss_5: 1.6596 - output_loss_6: 1.6204 - output_loss_7: 1.6068 - output_loss_8: 1.6040   \n",
      "Epoch 10/12\n",
      "661403/661403 [==============================] - 215s - loss: 14.7217 - output_loss_1: 2.4081 - output_loss_2: 2.1770 - output_loss_3: 1.9077 - output_loss_4: 1.7522 - output_loss_5: 1.6564 - output_loss_6: 1.6167 - output_loss_7: 1.6039 - output_loss_8: 1.5996   \n",
      "Epoch 11/12\n",
      "661403/661403 [==============================] - 217s - loss: 14.7053 - output_loss_1: 2.4078 - output_loss_2: 2.1763 - output_loss_3: 1.9066 - output_loss_4: 1.7505 - output_loss_5: 1.6535 - output_loss_6: 1.6141 - output_loss_7: 1.6003 - output_loss_8: 1.5963   \n",
      "Epoch 12/12\n",
      "661403/661403 [==============================] - 223s - loss: 14.6906 - output_loss_1: 2.4076 - output_loss_2: 2.1759 - output_loss_3: 1.9057 - output_loss_4: 1.7488 - output_loss_5: 1.6512 - output_loss_6: 1.6112 - output_loss_7: 1.5970 - output_loss_8: 1.5932   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f00511190>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zeros]+xs, ys, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts(m, inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict([np.zeros(n_fac)[np.newaxis,:]] + arrs)\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ', 'h', 'e', 't', ' ', 's', 'n', ' ']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(model, ' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_nexts(model, ' part of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'u', 'e', 'e', 'n', 's', ' ', 'a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['u', 'e', 'r', 'n', ' ', ' ', 't', 'n']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(model, 'queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence model with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert our previous keras model into a sequence model, simply add the `return_sequences=True` parameter, and add `TimeDistributed` around our dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_13 (Embedding)         (None, 8, 42)         3696        embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "simplernn_5 (SimpleRNN)          (None, 8, 256)        76544       embedding_13[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribute(None, 8, 88)         22616       simplernn_5[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 102856\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=nc),\n",
    "        SimpleRNN(n_hidden, return_sequences=True, activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661403,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_rnn = np.stack(np.squeeze(xs), axis=1)\n",
    "y_rnn = np.atleast_3d(np.stack(ys, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((661403, 8), (661403, 8, 1))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn.shape, y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "661403/661403 [==============================] - 133s - loss: 1.8399   \n",
      "Epoch 2/8\n",
      "661403/661403 [==============================] - 134s - loss: 1.6590   \n",
      "Epoch 3/8\n",
      "661403/661403 [==============================] - 123s - loss: 1.6273   \n",
      "Epoch 4/8\n",
      "661403/661403 [==============================] - 129s - loss: 1.6125   \n",
      "Epoch 5/8\n",
      "661403/661403 [==============================] - 123s - loss: 1.6031   \n",
      "Epoch 6/8\n",
      "661403/661403 [==============================] - 123s - loss: 1.5967   \n",
      "Epoch 7/8\n",
      "661403/661403 [==============================] - 123s - loss: 1.5919   \n",
      "Epoch 8/8\n",
      "661403/661403 [==============================] - 123s - loss: 1.5879   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0edc0ea610>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "661403/661403 [==============================] - 126s - loss: 1.5847   \n",
      "Epoch 2/4\n",
      "661403/661403 [==============================] - 130s - loss: 1.5823   \n",
      "Epoch 3/4\n",
      "661403/661403 [==============================] - 127s - loss: 1.5800   \n",
      "Epoch 4/4\n",
      "661403/661403 [==============================] - 124s - loss: 1.5782   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0edc0eab10>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size=64, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(m, inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p = m.predict(arrs)[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ', 'h', 'e', 's', ' ', 's', 's', ' ']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(model, ' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'p', 'a', 'r', 't', ' ', 'o', 'f']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ', 'r', 'r', 't', ' ', 'o', 'f', ' ']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(model, ' part of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'u', 'e', 'e', 'n', 's', ' ', 'a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['u', 'e', 's', 'n', ' ', ' ', 'a', 'n']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(model, 'queens a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save4_path = model_path + 'save4.h5'\n",
    "if not os.path.exists(save4_path):\n",
    "    model.save_weights(save4_path)\n",
    "model.load_weights(save4_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char RNN\n",
    "\n",
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/char-rnn.ipynb"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
